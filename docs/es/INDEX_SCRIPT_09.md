# ðŸ—ï¸ Arquitectura: El Mini Asistente Completo (Script 09)
ðŸŒ [English](../en/INDEX_SCRIPT_09.md) | ðŸ“– [FranÃ§ais](../fr/INDEX_SCRIPT_09.md) | ðŸ‡ªðŸ‡¸ **EspaÃ±ol** | ðŸ‡§ðŸ‡· [PortuguÃªs](../pt/INDEX_SCRIPT_09.md) | ðŸ‡¸ðŸ‡¦ [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](../ar/INDEX_SCRIPT_09.md)
> **Desglose completo** del proyecto integrador  
> Entendiendo la estructura tÃ©cnica: capas, componentes, flujo

---

## ðŸ“ NavegaciÃ³n RÃ¡pida

- **ðŸ“– Ver: [Recorrido PedagÃ³gico](PEDAGOGICAL_JOURNEY.md)** - CÃ³mo se conecta con los capÃ­tulos
- **âš¡ Ver: [Inicio RÃ¡pido](QUICKSTART_SCRIPT_09.md)** - Ejecuta en 5 minutos
- **ðŸ”— Ver: [Mapeo CÃ³digo â†” Conceptos](SCRIPT_09_MAPPING.md)** - QuÃ© cÃ³digo enseÃ±a quÃ©
- **ðŸŒ Otros idiomas: [English](../en/INDEX_SCRIPT_09.md) | [FranÃ§ais](../fr/INDEX_SCRIPT_09.md) | [PortuguÃªs](../pt/INDEX_SCRIPT_09.md)**

---

## ðŸŽ¯ Â¿QuÃ© Hay Dentro?

El Script 09 demuestra TODOS los conceptos de los capÃ­tulos 11-15:

| CapÃ­tulo | Concepto | Componente en Script 09 |
|----------|----------|------------------------|
| 11 | GeneraciÃ³n + Temperatura | `generate_with_temperature()` |
| 12 | Chain-of-Thought | `reasoning_phase()` |
| 13 | RAG + RecuperaciÃ³n | `retrieve_documents()` |
| 14 | Agentes ReAct | `agent_loop()` |
| 15 | EvaluaciÃ³n | `evaluate_response()` |

---

## ðŸ—ï¸ Arquitectura TÃ©cnica

### Capa 1: Capa de Datos
```
Base de Conocimientos (en memoria)
    â†“
FragmentaciÃ³n de Documentos
    â†“
Embeddings Vectoriales (numpy)
```

**Responsabilidad:** Almacenar e indexar conocimiento
**UbicaciÃ³n del cÃ³digo:** `load_knowledge_base()`, `embed_documents()`

---

### Capa 2: Capa de RecuperaciÃ³n (RAG)
```
Consulta del Usuario
    â†“
Embed de la Consulta
    â†“
BÃºsqueda por Similitud (coseno)
    â†“
Contextos Recuperados
```

**Responsabilidad:** Encontrar documentos relevantes
**UbicaciÃ³n del cÃ³digo:** `retrieve_documents()`

**FunciÃ³n Clave:**
```python
def retrieve_documents(query: str, k: int = 3) -> list:
    # 1. Embed de la consulta
    # 2. Calcular similitud con todos los documentos
    # 3. Retornar top-k mÃ¡s relevantes
```

---

### Capa 3: Capa de Razonamiento (Chain-of-Thought)
```
Pregunta
    â†“
Paso 1: Analizar problema
Paso 2: Recuperar contexto
Paso 3: Pensar paso a paso
    â†“
Traza de Razonamiento
```

**Responsabilidad:** Estructurar el pensamiento
**UbicaciÃ³n del cÃ³digo:** `reasoning_phase()`

---

### Capa 4: Capa de GeneraciÃ³n (similar a LLM)
```
Traza de Razonamiento + Contexto
    â†“
SelecciÃ³n de Token (softmax)
    â†“
Muestreo con Temperatura
    â†“
GeneraciÃ³n de Respuesta
```

**Responsabilidad:** Crear texto
**UbicaciÃ³n del cÃ³digo:** `generate_with_temperature()`

---

### Capa 5: Capa de Agente (ReAct)
```
DecisiÃ³n del Agente (Pensar)
    â†“
SelecciÃ³n de Herramienta (Actuar)
    â†“
Observar Resultado
    â†“
Bucle hasta terminar
```

**Responsabilidad:** EjecuciÃ³n autÃ³noma
**UbicaciÃ³n del cÃ³digo:** `agent_loop()`

---

### Capa 6: Capa de EvaluaciÃ³n
```
Respuesta Generada
    â†“
MÃºltiples MÃ©tricas (BLEU, Similitud de Embeddings, Coherencia)
    â†“
PuntuaciÃ³n (0-100)
```

**Responsabilidad:** EvaluaciÃ³n de calidad
**UbicaciÃ³n del cÃ³digo:** `evaluate_response()`

---

## ðŸ”„ Flujo de EjecuciÃ³n Completo

```
Entrada del Usuario
    â†“
embed_documents() â†’ Vectores de documentos (128-dim)
    â†“
retrieve_documents() â†’ Top-k documentos similares
    â†“
reasoning_phase() â†’ Pensamiento estructurado
    â†“
generate_with_temperature() â†’ GeneraciÃ³n de texto
    â†“
agent_loop() â†’ IteraciÃ³n autÃ³noma
    â†“
evaluate_response() â†’ MÃ©tricas de calidad
    â†“
Salida al Usuario
```

**Paso a paso:**

1. **Procesamiento de Entrada**
   - Parsear consulta del usuario
   - Preparar para recuperaciÃ³n

2. **RecuperaciÃ³n (RAG)**
   - Encontrar contexto relevante de la base de conocimientos
   - Retornar top-3 documentos

3. **Razonamiento**
   - Crear cadena de pensamiento
   - Analizar problema paso a paso
   - Incluir contexto recuperado

4. **GeneraciÃ³n**
   - Seleccionar tokens usando softmax
   - Aplicar muestreo con temperatura
   - Construir respuesta iterativamente

5. **Bucle del Agente**
   - Decidir: Â¿continuar o parar?
   - Seleccionar herramienta si es necesario
   - Ejecutar y observar

6. **EvaluaciÃ³n**
   - Calcular 5 mÃ©tricas de calidad
   - Retornar resultado con puntuaciÃ³n

7. **Retorno**
   - Presentar respuesta al usuario
   - Mostrar mÃ©tricas y traza

---

## ðŸ“¦ Funciones Principales

### `load_knowledge_base() â†’ dict`
```python
# Retorna diccionario de documentos
{
    'doc_1': "Contenido sobre IA...",
    'doc_2': "Contenido sobre LLMs...",
    ...
}
```

---

### `embed_documents(docs: dict) â†’ np.ndarray`
```python
# Retorna matriz (num_docs, embedding_dim)
# Simple: Embeddings basados en hash para demo
# Real: Usar embeddings de SentenceTransformer
```

---

### `retrieve_documents(query: str, k: int = 3) â†’ list`
```python
# Entrada: "Â¿QuÃ© es un LLM?"
# Salida: [
#   {'doc': 'doc_1', 'content': '...', 'similarity': 0.87},
#   {'doc': 'doc_2', 'content': '...', 'similarity': 0.76},
#   {'doc': 'doc_3', 'content': '...', 'similarity': 0.68}
# ]
```

---

### `reasoning_phase(question: str, contexts: list) â†’ str`
```python
# Entrada: pregunta + contextos recuperados
# Salida: Traza de pensamiento estructurado
"""
Paso 1: Analizar la pregunta
El usuario pregunta sobre LLMs...

Paso 2: Identificar conceptos clave
Conceptos: arquitectura, entrenamiento, inferencia...

Paso 3: Recuperar contexto relevante
Del documento X, sabemos que...

Paso 4: Sintetizar
Combinando el conocimiento, podemos concluir...
"""
```

---

### `generate_with_temperature(prompt: str, temp: float = 1.0) â†’ str`
```python
# Temperatura baja (0.3): determinÃ­stico, enfocado
# Temperatura media (1.0): balanceado
# Temperatura alta (2.0): creativo, diverso

# Retorna segmento de texto generado
```

---

### `agent_loop(initial_query: str, max_turns: int = 3) â†’ dict`
```python
# EjecuciÃ³n agÃ©ntica
# Cada turno: Pensar â†’ Actuar â†’ Observar

# Retorna: {
#   'answer': 'Respuesta final',
#   'turns': 3,
#   'trace': ['Turno 1: ...', 'Turno 2: ...', ...]
# }
```

---

### `evaluate_response(response: str, context: str) â†’ dict`
```python
# Calcula 5 mÃ©tricas:
# - Ratio de longitud
# - SuperposiciÃ³n de vocabulario (BLEU)
# - Similitud de embeddings
# - PuntuaciÃ³n de coherencia
# - Calidad general (0-100)

# Retorna: {
#   'metrics': {'bleu': 0.75, 'similarity': 0.82, ...},
#   'quality_score': 79,
#   'interpretation': 'Buena respuesta...'
# }
```

---

## âš™ï¸ ConfiguraciÃ³n y ParÃ¡metros

| ParÃ¡metro | Default | Rango | Efecto |
|-----------|---------|-------|--------|
| `TEMPERATURE` | 1.0 | 0.0-2.0 | Control de creatividad |
| `K_DOCUMENTS` | 3 | 1-10 | TamaÃ±o de contexto |
| `MAX_TURNS` | 3 | 1-10 | Iteraciones del agente |
| `EMBEDDING_DIM` | 128 | 64-512 | TamaÃ±o de embedding |

**CÃ³mo modificar:**
```python
# En script 09
TEMPERATURE = 1.5        # MÃ¡s creativo
K_DOCUMENTS = 5          # MÃ¡s contexto
MAX_TURNS = 5            # MÃ¡s iteraciones del agente
```

---

## ðŸ’¡ Detalles Clave de ImplementaciÃ³n

### Embeddings (Demo Simplificado)
```python
# ProducciÃ³n real: SentenceTransformer
# VersiÃ³n demo: Basado en hash (determinÃ­stico, rÃ¡pido)

def simple_embedding(text: str, dim: int = 128) -> np.ndarray:
    hash_val = hash(text)
    np.random.seed(abs(hash_val) % 2**32)
    return np.random.randn(dim)
```

---

### Muestreo con Temperatura
```python
# Temperatura = factor de escala para softmax
# logits = [1.0, 2.0, 0.5]
# 
# T=0.5: softmax(logits / 0.5) â†’ mÃ¡s agudo [0.1, 0.87, 0.03]
# T=1.0: softmax(logits / 1.0) â†’ normal [0.09, 0.67, 0.24]
# T=2.0: softmax(logits / 2.0) â†’ mÃ¡s plano [0.28, 0.38, 0.34]
```

---

### Prompting Chain-of-Thought
```
En lugar de: "Â¿QuÃ© es X?"
Mejor:       "Pensemos paso a paso:
              1. Definir el concepto
              2. Desglosarlo
              3. Proporcionar ejemplos
              4. Concluir"
```

---

### ImplementaciÃ³n del Bucle ReAct
```python
while not done and turns < max_turns:
    # PENSAR: Analizar estado actual
    thought = analyze_state(context)
    
    # ACTUAR: Elegir y ejecutar herramienta/acciÃ³n
    action = select_action(thought)
    result = execute_action(action)
    
    # OBSERVAR: Actualizar conocimiento
    observation = observe_result(result)
    
    turns += 1
```

---

## ðŸŽ¯ Resultados de Aprendizaje

DespuÃ©s de estudiar esta arquitectura, entiendes:

âœ… CÃ³mo RAG integra recuperaciÃ³n con generaciÃ³n  
âœ… CÃ³mo la temperatura afecta el comportamiento del modelo  
âœ… CÃ³mo Chain-of-Thought mejora el razonamiento  
âœ… CÃ³mo los agentes toman decisiones autÃ³nomas  
âœ… CÃ³mo evaluar la calidad de generaciÃ³n  
âœ… CÃ³mo combinar todos estos conceptos en un sistema  

---

## ðŸš€ Siguientes Pasos

1. **Ejecuta:** [GuÃ­a de Inicio RÃ¡pido](QUICKSTART_SCRIPT_09.md)
2. **Entiende el cÃ³digo:** [Mapeo CÃ³digo â†” Conceptos](SCRIPT_09_MAPPING.md)
3. **AdÃ¡ptalo:** Modifica para tu caso de uso
4. **ExtiÃ©ndelo:** Agrega mÃ¡s herramientas, mejores embeddings, etc.

---

**Â¿Listo para profundizar? ðŸ“š**
