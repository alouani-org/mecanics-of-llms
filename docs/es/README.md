
# Scripts Pr√°cticos: Experimentando con Conceptos de LLM

üåç [English](../en/README.md) | üìñ [Fran√ßais](../fr/README.md) | üá™üá∏ **Espa√±ol** | üáßüá∑ [Portugu√™s](../pt/README.md) | üá∏üá¶ [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](../ar/README.md)

Colecci√≥n de **10 scripts de Python ejecutables** para experimentar con los conceptos clave del libro **"La Mec√°nica de los LLM"**.

> üìö **Acerca de** : Estos scripts acompa√±an los cap√≠tulos del libro. Ver [Recorrido Pedag√≥gico](PEDAGOGICAL_JOURNEY.md) para las correspondencias detalladas.

**üìï Comprar el Libro:**
- **Impreso** : [Amazon](https://amzn.eu/d/3oREERI)
- **Kindle** : [Amazon](https://amzn.eu/d/b7sG5iw)

---

## üìã Vista General de los Scripts

| # | Script | Cap√≠tulo(s) | Conceptos | Estado |
|---|--------|-------------|-----------|--------|
| 1 | `01_tokenization_embeddings.py` | 2 | Tokenizaci√≥n, impacto en longitud de secuencia | ‚úÖ |
| 2 | `02_multihead_attention.py` | 3 | Self-attention, multi-head, pesos de atenci√≥n | ‚úÖ |
| 3 | `03_temperature_softmax.py` | 7, 11 | Temperatura, softmax, entrop√≠a | ‚úÖ |
| 4 | `04_rag_minimal.py` | 13 | Pipeline RAG, recuperaci√≥n, similitud coseno | ‚úÖ |
| 5 | `05_pass_at_k_evaluation.py` | 12 | Pass@k, Pass^k, evaluaci√≥n de modelos | ‚úÖ |
| üéÅ 6 | `06_react_agent_bonus.py` | 14, 15 | **Agentes ReAct, registro de herramientas, MCP** | ‚úÖ BONUS |
| üéÅ 7 | `07_llamaindex_rag_advanced.py` | 13, 14 | **RAG avanzado, indexaci√≥n, chat persistente** | ‚úÖ BONUS |
| üéÅ 8 | `08_lora_finetuning_example.py` | 9, 10 | **LoRA, QLoRA, comparaci√≥n de fine-tuning** | ‚úÖ BONUS |
| üèÜ **9** | `09_mini_assistant_complet.py` | **11-15** | **üéØ Proyecto Integrador Final** | ‚úÖ PRINCIPAL |
| üéÅ 10 | `10_activation_steering_demo.py` | 10 | **Activation Steering, 3SO, vectores de concepto** | ‚úÖ BONUS |

---

## üìñ Descripciones Detalladas de los Scripts

### üìå Script 01: Tokenizaci√≥n y Embeddings
**Archivo:** `01_tokenization_embeddings.py` | **Cap√≠tulo:** 2

**Lo que hace el script:**
- Carga un tokenizador (GPT-2 o LLaMA-2) y analiza diferentes textos
- Compara el n√∫mero de tokens entre franc√©s e ingl√©s
- Demuestra el impacto de la longitud de secuencia en el costo computacional

**Lo que aprendes:**
- C√≥mo el texto se divide en tokens (BPE, WordPiece)
- Por qu√© "Bonjour" puede convertirse en 2-3 tokens mientras "Hello" es solo uno
- El impacto directo: m√°s tokens = mayor costo O(n¬≤) para la atenci√≥n

**Salida esperada:**
```
Text: L'IA est utile
  Token count: 5
  Tokens: ['L', "'", 'IA', 'est', 'utile']
```

---

### üìå Script 02: Atenci√≥n Multi-Cabezas
**Archivo:** `02_multihead_attention.py` | **Cap√≠tulo:** 3

**Lo que hace el script:**
- Simula una capa de atenci√≥n multi-cabezas con tensores PyTorch
- Calcula las proyecciones Q, K, V y los pesos de atenci√≥n
- Muestra c√≥mo cada cabeza "mira" la oraci√≥n de manera diferente

**Lo que aprendes:**
- El mecanismo Q (Query), K (Key), V (Value)
- Por qu√© m√∫ltiples cabezas capturan diferentes dependencias
- Que los pesos de atenci√≥n siempre suman 1 (distribuci√≥n de probabilidad)

**Salida esperada:**
```
Sentence: The cat sleeps well
Head 1: Attention weights from 'cat' ‚Üí 'sleeps': 0.42
Head 2: Attention weights from 'cat' ‚Üí 'The': 0.38
```

---

### üìå Script 03: Temperatura y Softmax
**Archivo:** `03_temperature_softmax.py` | **Cap√≠tulos:** 7, 11

**Lo que hace el script:**
- Aplica softmax con diferentes temperaturas (0.1, 0.5, 1.0, 2.0)
- Calcula la entrop√≠a de Shannon para cada distribuci√≥n
- Genera gr√°ficos (si matplotlib est√° instalado)

**Lo que aprendes:**
- T < 1: distribuci√≥n "aguda" ‚Üí generaci√≥n determin√≠stica (greedy)
- T > 1: distribuci√≥n "plana" ‚Üí generaci√≥n creativa/diversa
- La entrop√≠a aumenta con la temperatura (m√°s incertidumbre)

**Salida esperada:**
```
Temperature 0.5: Token 'Paris' = 85% (agudo, determin√≠stico)
Temperature 2.0: Token 'Paris' = 35% (plano, creativo)
```

---

### üìå Script 04: RAG M√≠nimo
**Archivo:** `04_rag_minimal.py` | **Cap√≠tulo:** 13

**Lo que hace el script:**
- Crea una mini base de conocimientos (7 documentos sobre LLMs)
- Vectoriza los documentos con TF-IDF
- Realiza b√∫squeda por similitud coseno
- Simula la generaci√≥n aumentada por el contexto recuperado

**Lo que aprendes:**
- El pipeline RAG completo: Recuperaci√≥n ‚Üí Aumentaci√≥n ‚Üí Generaci√≥n
- C√≥mo la similitud coseno encuentra los documentos relevantes
- Por qu√© RAG permite responder preguntas sobre datos privados

**Salida esperada:**
```
Pregunta: "¬øC√≥mo funciona la atenci√≥n en el Transformer?"
‚Üí Documentos recuperados: [doc_1: 0.72, doc_4: 0.65]
‚Üí Respuesta generada con contexto
```

---

### üìå Script 05: Evaluaci√≥n Pass@k
**Archivo:** `05_pass_at_k_evaluation.py` | **Cap√≠tulo:** 12

**Lo que hace el script:**
- Simula 100 intentos de generaci√≥n con una tasa de √©xito del 30%
- Calcula Pass@k (al menos 1 √©xito en k intentos)
- Calcula Pass^k (todos los k intentos exitosos)

**Lo que aprendes:**
- Pass@k = 1 - (1-p)^k: probabilidad de al menos un √©xito
- Pass^k = p^k: probabilidad de que todos tengan √©xito (muy estricto)
- Por qu√© Pass@10 ‚âà 97% incluso con p=30% (tienes 10 oportunidades)

**Salida esperada:**
```
Pass@1  = 30%  (oportunidad con 1 intento)
Pass@5  = 83%  (oportunidad con 5 intentos)
Pass@10 = 97%  (casi seguro con 10 intentos)
```

---

### üéÅ Script 06: Agente ReAct (BONUS)
**Archivo:** `06_react_agent_bonus.py` | **Cap√≠tulos:** 14, 15

**Lo que hace el script:**
- Implementa un mini framework de agentes aut√≥nomos
- Demuestra el bucle ReAct: Thought ‚Üí Action ‚Üí Observation ‚Üí ...
- Incluye herramientas simuladas: calculadora, b√∫squeda web, clima

**Lo que aprendes:**
- El patr√≥n ReAct (Razonamiento + Acci√≥n)
- C√≥mo un agente decide qu√© acci√≥n tomar
- Auto-correcci√≥n: el agente puede reintentar si una acci√≥n falla
- La base para entender agentes MCP (Model Context Protocol)

**Salida esperada:**
```
Thought: Necesito calcular el 15% de $250
Action: calculator(250 * 0.15)
Observation: 37.5
Final Answer: La propina es de $37.50
```

---

### üéÅ Script 07: RAG Avanzado con LlamaIndex (BONUS)
**Archivo:** `07_llamaindex_rag_advanced.py` | **Cap√≠tulos:** 13, 14

**Lo que hace el script:**
- Sistema RAG completo con parsing de documentos
- Indexaci√≥n y embeddings (simulados o reales con OpenAI)
- Chat con memoria conversacional
- Evaluaci√≥n de calidad (Precisi√≥n, Recall, F1)

**Lo que aprendes:**
- Arquitectura RAG de producci√≥n: ingesti√≥n ‚Üí indexaci√≥n ‚Üí recuperaci√≥n ‚Üí generaci√≥n
- C√≥mo mantener el contexto a trav√©s de m√∫ltiples turnos de conversaci√≥n
- C√≥mo evaluar la calidad de un sistema RAG

**Salida esperada:**
```
[Modo Chat]
Usuario: ¬øQu√© es un Transformer?
Asistente: [Contexto: 3 docs] Un Transformer es...
Usuario: ¬øY la atenci√≥n multi-cabezas?
Asistente: [Memoria: pregunta anterior + 2 docs] ...
```

---

### üéÅ Script 08: Fine-tuning LoRA/QLoRA (BONUS)
**Archivo:** `08_lora_finetuning_example.py` | **Cap√≠tulos:** 9, 10

**Lo que hace el script:**
- Compara Full Fine-tuning vs LoRA vs QLoRA (c√°lculos num√©ricos)
- Muestra los ahorros de VRAM y par√°metros entrenables
- Caso de uso: adaptar LLaMA-7B para un dominio empresarial (ferrocarril)

**Lo que aprendes:**
- LoRA: a√±ade ~0.1% de par√°metros vs fine-tuning completo
- QLoRA: cuantizaci√≥n de 4 bits + LoRA = GPU de 24GB en lugar de 140GB
- Por qu√© el fine-tuning eficiente democratiza los LLMs

**Salida esperada:**
```
LLaMA-7B:
  Full Fine-tuning: 28 GB VRAM, 7B params
  LoRA (rank=8):    8 GB VRAM, 4.2M params (0.06%)
  QLoRA:            6 GB VRAM, 4.2M params + base 4-bit
```

---

### ÔøΩ Script 10: Activation Steering & 3SO (BONUS)
**Archivo:** `10_activation_steering_demo.py` | **Cap√≠tulo:** 10

**Lo que hace el script:**
- Demuestra el steering por activaciones: inyecci√≥n de vectores de concepto
- Implementa extracci√≥n de vectores por activaci√≥n contrastiva
- Simula un Sparse Autoencoder (SAE) para descomposici√≥n en conceptos
- Implementa una m√°quina de estados finitos para 3SO (salidas JSON garantizadas)
- Compara RLHF/DPO vs Steering con tabla detallada

**Lo que aprendes:**
- El steering modifica las activaciones en inferencia: $X_{steered} = X + (c \times V)$
- C√≥mo extraer vectores de concepto (m√©todo contrastivo, SAE)
- Impacto del coeficiente de steering (muy bajo ‚Üí nulo, √≥ptimo ‚Üí efectivo, muy alto ‚Üí descarrilamiento)
- El 3SO garantiza matem√°ticamente una sintaxis JSON v√°lida
- Cu√°ndo usar alineamiento vs steering

**Salida esperada:**
```
STEP 3: Analyzing Coefficient Effect
   Coeff   Direction Œî     Perturbation    Stability
   1.0     12.5¬∞           8.2%            ‚úÖ stable
   5.0     45.3¬∞           35.1%           ‚ö†Ô∏è moderate
   15.0    78.2¬∞           89.4%           ‚ùå unstable
```

---

### ÔøΩüèÜ Script 09: Mini-Asistente Completo (PROYECTO FINAL)
**Archivo:** `09_mini_assistant_complet.py` | **Cap√≠tulos:** 11-15

**Lo que hace el script:**
- Integra TODOS los conceptos: RAG + Agentes + Temperatura + Evaluaci√≥n
- Sistema completo con base de conocimientos, recuperaci√≥n, razonamiento
- Modo interactivo para probar diferentes preguntas

**Lo que aprendes:**
- C√≥mo ensamblar un asistente IA completo de A a Z
- Arquitectura en capas: Datos ‚Üí Recuperaci√≥n ‚Üí Razonamiento ‚Üí Generaci√≥n
- Evaluaci√≥n de extremo a extremo de un sistema

**Documentaci√≥n dedicada:**
- [INDEX_SCRIPT_09.md](INDEX_SCRIPT_09.md): Arquitectura completa
- [QUICKSTART_SCRIPT_09.md](QUICKSTART_SCRIPT_09.md): Inicio r√°pido en 5 min
- [SCRIPT_09_MAPPING.md](SCRIPT_09_MAPPING.md): Mapeo c√≥digo ‚Üî conceptos

---

## üöÄ Inicio R√°pido

### 1. Crear un Entorno Virtual (recomendado)

```bash
# En Windows
python -m venv venv
venv\Scripts\activate

# En macOS / Linux
python -m venv venv
source venv/bin/activate
```

### 2. Instalar Dependencias

```bash
# Instalaci√≥n b√°sica (para scripts 1-5)
pip install torch transformers numpy scikit-learn

# Instalaci√≥n completa (con visualizaciones)
pip install torch transformers numpy scikit-learn matplotlib

# Para scripts bonus (opcional, funcionan en modo demo sin estas)
pip install llama-index openai python-dotenv peft bitsandbytes
```

**Nota:** Los scripts bonus (06, 07, 08) funcionan **sin dependencias externas** en modo demo.

### 3. Ejecutar un Script

```bash
python 01_tokenization_embeddings.py
python 02_multihead_attention.py
python 03_temperature_softmax.py
python 04_rag_minimal.py
python 05_pass_at_k_evaluation.py
python 06_react_agent_bonus.py
python 07_llamaindex_rag_advanced.py
python 08_lora_finetuning_example.py
python 09_mini_assistant_complet.py    # ‚Üê Proyecto integrador final
```

---

## üèÜ Proyecto Integrador: Mini-Asistente Completo

**EL script principal**: integra TODOS los conceptos de los cap√≠tulos 11-15.

- **Script:** `09_mini_assistant_complet.py`
- **Documentaci√≥n:** [INDEX_SCRIPT_09.md](INDEX_SCRIPT_09.md)
- **Inicio R√°pido:** [QUICKSTART_SCRIPT_09.md](QUICKSTART_SCRIPT_09.md)
- **Arquitectura:** [SCRIPT_09_MAPPING.md](SCRIPT_09_MAPPING.md)

---

## üìñ Documentaci√≥n Completa

- **[Recorrido Pedag√≥gico](PEDAGOGICAL_JOURNEY.md)**: Correspondencia cap√≠tulo por cap√≠tulo libro ‚Üî scripts
- **[Agentes ReAct](REACT_AGENT_INTEGRATION.md)**: Patr√≥n ReAct e integraci√≥n
- **[LlamaIndex RAG](LLAMAINDEX_GUIDE.md)**: Framework RAG avanzado

---

## üìù Notas

- **No se requiere GPU**: todos los scripts funcionan en CPU (m√°s lento)
- **C√≥digo educativo**: prioriza la claridad sobre la optimizaci√≥n
- **Compatible con Python 3.9+**

---

**¬°Feliz aprendizaje! üöÄ**
