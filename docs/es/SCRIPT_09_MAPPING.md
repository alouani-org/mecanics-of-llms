# üîó Mapeo C√≥digo ‚Üî Concepto: Script 09
üåç [English](../en/SCRIPT_09_MAPPING.md) | üìñ [Fran√ßais](../fr/SCRIPT_09_MAPPING.md) | üá™üá∏ **Espa√±ol** | üáßüá∑ [Portugu√™s](../pt/SCRIPT_09_MAPPING.md) | üá∏üá¶ [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](../ar/SCRIPT_09_MAPPING.md)
> **Entiende qu√© c√≥digo implementa qu√© concepto**  
> Gu√≠a de aprendizaje l√≠nea por l√≠nea

---

## üìç Navegaci√≥n R√°pida

- **üìñ Ver: [Recorrido Pedag√≥gico](PEDAGOGICAL_JOURNEY.md)** - Teor√≠a
- **üèóÔ∏è Ver: [Arquitectura](INDEX_SCRIPT_09.md)** - Estructura
- **‚ö° Ver: [Inicio R√°pido](QUICKSTART_SCRIPT_09.md)** - Ejec√∫talo
- **üåç Otros idiomas: [English](../en/SCRIPT_09_MAPPING.md) | [Fran√ßais](../fr/SCRIPT_09_MAPPING.md) | [Portugu√™s](../pt/SCRIPT_09_MAPPING.md)**

---

## üéØ Secci√≥n 1: Imports y Setup

### Concepto: Preparaci√≥n del Entorno

```python
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from collections import defaultdict
import re
```

**Lo que ense√±a:**
- `numpy`: Computaci√≥n num√©rica (embeddings, softmax)
- `cosine_similarity`: Calcular similitud entre documentos
- `defaultdict`: Estructura de datos para base de conocimientos
- `re`: Procesamiento de texto

---

## üéØ Secci√≥n 2: Base de Conocimientos

### Concepto: Almacenamiento de Datos

```python
KNOWLEDGE_BASE = {
    'doc_1': "Un LLM es un modelo de lenguaje grande...",
    'doc_2': "Los Transformers usan mecanismos de atenci√≥n...",
    'doc_3': "RAG combina recuperaci√≥n con generaci√≥n...",
    # ... m√°s documentos
}
```

**Lo que ense√±a:**
- C√≥mo almacenar conocimiento de dominio
- Estructura simple de diccionario
- Escalable a miles de documentos

---

## üéØ Secci√≥n 3: Embeddings

### Concepto: Texto ‚Üí Representaci√≥n Vectorial

```python
def create_embedding(text: str, dim: int = 128) -> np.ndarray:
    """Convierte texto a vector usando hash determin√≠stico"""
    hash_val = hash(text)
    np.random.seed(abs(hash_val) % 2**32)
    return np.random.randn(dim)
```

**Lo que ense√±a:**
- **Producci√≥n real:** Usar SentenceTransformer
  ```python
  from sentence_transformers import SentenceTransformer
  model = SentenceTransformer('all-MiniLM-L6-v2')
  embedding = model.encode(text)
  ```
- **En esta demo:** Enfoque simplificado basado en hash para velocidad
- **Concepto clave:** Texto ‚Üí vector de tama√±o fijo (128 dimensiones)
- **Propiedad:** Texto similar ‚Üí vectores similares

**Analog√≠a del mundo real:**
```
Imagina: Cada documento es un punto en espacio de 128 dimensiones
Puntos cercanos = significado similar
```

---

## üéØ Secci√≥n 4: Recuperaci√≥n (RAG Parte 1)

### Concepto: Encontrar Documentos Relevantes

```python
def retrieve_documents(query: str, k: int = 3) -> list:
    """Paso 1: Embed de la consulta
       Paso 2: Comparar con todos los documentos
       Paso 3: Retornar top-k m√°s similares
    """
    query_embedding = create_embedding(query)
    
    # Crear matriz de todos los embeddings de documentos
    doc_embeddings = np.array([
        create_embedding(doc) 
        for doc in KNOWLEDGE_BASE.values()
    ])
    
    # Calcular similitud coseno
    similarities = cosine_similarity(
        query_embedding.reshape(1, -1), 
        doc_embeddings
    )[0]
    
    # Obtener top-k
    top_indices = np.argsort(similarities)[-k:][::-1]
    
    results = []
    for idx in top_indices:
        doc_name = list(KNOWLEDGE_BASE.keys())[idx]
        results.append({
            'doc': doc_name,
            'content': KNOWLEDGE_BASE[doc_name],
            'similarity': similarities[idx]
        })
    
    return results
```

**Lo que ense√±a:**
- **Embedding:** Convertir texto a vector
- **Similitud:** Similitud coseno = ¬øqu√© tan alineados est√°n dos vectores?
  ```
  cosine_similarity = (A ¬∑ B) / (||A|| * ||B||)
  Rango: -1 (opuesto) a 1 (id√©ntico)
  ```
- **Selecci√≥n:** Retornar top-k (m√°s similares) documentos
- **Complejidad:** O(n*d) donde n=docs, d=dimensiones

**Analog√≠a del mundo real:**
```
Como un bibliotecario:
1. Lee tu pregunta
2. Compara mentalmente con todos los libros
3. Te trae los 3 libros m√°s relevantes
```

---

## üéØ Secci√≥n 5: Razonamiento (Chain-of-Thought)

### Concepto: Resoluci√≥n Estructurada de Problemas

```python
def reasoning_phase(question: str, contexts: list) -> str:
    """Piensa paso a paso con contexto recuperado"""
    
    reasoning = f"""
    Paso 1: Analizar la Pregunta
    El usuario pregunta sobre: {question}
    
    Paso 2: Conceptos Clave
    Extraer conceptos principales de la pregunta
    
    Paso 3: Recuperar Contexto Relevante
    De los documentos recuperados:
    """
    
    for i, ctx in enumerate(contexts, 1):
        reasoning += f"\n- De {ctx['doc']}: {ctx['content'][:100]}..."
    
    reasoning += f"""
    
    Paso 4: Sintetizar una Respuesta
    Combinando el conocimiento:
    - Punto 1: [del contexto 1]
    - Punto 2: [del contexto 2]
    - Punto 3: [del contexto 3]
    
    Conclusi√≥n: Basado en lo anterior, podemos concluir...
    """
    
    return reasoning
```

**Lo que ense√±a:**
- **Chain-of-Thought:** Dividir problema en pasos
- **Integraci√≥n de Contexto:** Usar documentos recuperados
- **Reproducibilidad:** Cada paso es visible
- **Transparencia:** F√°cil de depurar el razonamiento

**Analog√≠a del mundo real:**
```
Como mostrar tu trabajo en matem√°ticas:
No solo "respuesta: 42"
Sino "Paso 1: ... Paso 2: ... Paso 3: ... Respuesta: 42"
```

---

## üéØ Secci√≥n 6: Generaci√≥n con Temperatura

### Concepto: Softmax y Muestreo con Temperatura

```python
def generate_with_temperature(
    prompt: str, 
    temperature: float = 1.0
) -> str:
    """
    Simula generaci√≥n de tokens con control de temperatura
    
    Temperatura:
    - 0.1: Muy enfocado (determin√≠stico)
    - 1.0: Balanceado (softmax normal)
    - 2.0: Muy creativo (diverso)
    """
    
    # Simular logits (puntuaciones no normalizadas)
    prompt_hash = hash(prompt)
    np.random.seed(abs(prompt_hash) % 2**32)
    logits = np.random.randn(100) * 2
    
    # Aplicar escalado de temperatura
    scaled_logits = logits / temperature
    
    # Softmax para obtener probabilidades
    exp_logits = np.exp(scaled_logits - np.max(scaled_logits))
    probabilities = exp_logits / np.sum(exp_logits)
    
    # Muestrear token
    selected_idx = np.random.choice(100, p=probabilities)
    
    # Generar texto
    vocab = ["un", "LLM", "es", "un", "modelo", "que", 
             "genera", "texto", "usando", "redes", "neuronales"]
    response = " ".join([vocab[i % len(vocab)] for i in range(selected_idx % 20)])
    
    return response
```

**Lo que ense√±a:**

**F√≥rmula Softmax:**
```
softmax(x_i) = exp(x_i) / sum(exp(x_j))
Resultado: distribuci√≥n de probabilidad (suma = 1)
```

**Efecto de Temperatura:**
```
T = 0.1  ‚Üí  [0.01, 0.98, 0.01]  ‚Üê Agudo (determin√≠stico)
T = 1.0  ‚Üí  [0.15, 0.70, 0.15]  ‚Üê Balanceado
T = 2.0  ‚Üí  [0.30, 0.40, 0.30]  ‚Üê Plano (diverso)
```

**Insight clave:**
- T baja: El modelo repite el token m√°s probable (aburrido)
- T alta: El modelo explora alternativas (creativo)

---

## üéØ Secci√≥n 7: Bucle del Agente (ReAct)

### Concepto: Toma de Decisiones Aut√≥noma

```python
def agent_loop(
    initial_query: str, 
    max_turns: int = 3
) -> dict:
    """
    Patr√≥n ReAct:
    PENSAR ‚Üí ACTUAR ‚Üí OBSERVAR ‚Üí (repetir)
    """
    
    context = initial_query
    trace = []
    turn = 0
    
    while turn < max_turns:
        turn += 1
        
        # PENSAR: Analizar estado actual
        thought = f"Turno {turn}: Analizando '{context[:50]}...'"
        trace.append(f"PENSAR: {thought}")
        
        # Decidir: ¬øContinuar o Parar?
        should_continue = turn < max_turns and len(context) < 500
        
        if not should_continue:
            trace.append("PARAR: Suficiente informaci√≥n recopilada")
            break
        
        # ACTUAR: Recuperar documentos
        documents = retrieve_documents(context, k=2)
        trace.append(f"ACTUAR: Recuperados {len(documents)} documentos")
        
        # OBSERVAR: Procesar resultados
        context += f" [Recuperado: {documents[0]['doc']}]"
        trace.append(f"OBSERVAR: A√±adido contexto de {documents[0]['doc']}")
    
    return {
        'answer': context,
        'turns': turn,
        'trace': trace
    }
```

**Lo que ense√±a:**

**Bucle ReAct:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PENSAR (analizar estado)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ACTUAR (tomar acci√≥n/recuperar) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ OBSERVAR (procesar resultados)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
        ¬øRepetir o Parar?
```

**Propiedades clave:**
- Aut√≥nomo: Toma decisiones independientemente
- Observable: Cada paso est√° rastreado
- Iterativo: Mejora con cada turno
- Detenible: Sabe cu√°ndo parar

---

## üéØ Secci√≥n 8: M√©tricas de Evaluaci√≥n

### Concepto: Evaluaci√≥n de Calidad

```python
def evaluate_response(response: str, context: str) -> dict:
    """Calcula m√∫ltiples m√©tricas de calidad"""
    
    # M√©trica 1: Ratio de Longitud
    length_ratio = min(len(response), 500) / 500
    
    # M√©trica 2: BLEU-like (superposici√≥n de vocabulario)
    response_words = set(response.lower().split())
    context_words = set(context.lower().split())
    overlap = len(response_words & context_words)
    vocabulary_overlap = overlap / max(len(response_words), 1)
    
    # M√©trica 3: Similitud de Embeddings
    response_emb = create_embedding(response)
    context_emb = create_embedding(context)
    similarity = cosine_similarity(
        response_emb.reshape(1, -1),
        context_emb.reshape(1, -1)
    )[0][0]
    
    # M√©trica 4: Coherencia (diversidad de tokens)
    tokens = response.lower().split()
    unique_ratio = len(set(tokens)) / max(len(tokens), 1)
    coherence = 0.5 + 0.5 * (1 - unique_ratio)  # Balanceado
    
    # M√©trica 5: Calidad General
    quality_score = (
        length_ratio * 0.2 +
        vocabulary_overlap * 0.3 +
        similarity * 0.25 +
        coherence * 0.25
    ) * 100
    
    return {
        'metrics': {
            'length_ratio': length_ratio,
            'vocabulary_overlap': vocabulary_overlap,
            'embedding_similarity': similarity,
            'coherence': coherence
        },
        'quality_score': quality_score,
        'interpretation': interpret_score(quality_score)
    }
```

**Lo que ense√±a:**

**Tipos de M√©tricas:**

1. **Ratio de Longitud**: 0-1
   - Asegura que la respuesta no sea muy corta/larga
   
2. **BLEU Score**: 0-1
   - ¬øCu√°ntas palabras se superponen con el contexto?
   
3. **Similitud de Embeddings**: -1 a 1
   - ¬øSon respuesta y contexto sem√°nticamente similares?
   
4. **Coherencia**: 0-1
   - ¬øEvita la respuesta la repetici√≥n?
   
5. **Calidad General**: 0-100
   - Combinaci√≥n ponderada de las anteriores

**¬øPor qu√© m√∫ltiples m√©tricas?**
```
Una sola m√©trica = imagen incompleta
Ejemplo: Una respuesta corta y gen√©rica podr√≠a puntuar alto en 
         vocabulary_overlap pero bajo en length_ratio
```

---

## üéì Lista de Verificaci√≥n de Aprendizaje

Despu√©s de leer esto, deber√≠as entender:

- [ ] C√≥mo el texto se convierte en vectores (embeddings)
- [ ] C√≥mo se calcula la similitud (similitud coseno)
- [ ] C√≥mo se recuperan documentos (b√∫squeda k-NN)
- [ ] C√≥mo se estructura el razonamiento (Chain-of-Thought)
- [ ] C√≥mo la temperatura afecta la aleatoriedad (escalado softmax)
- [ ] C√≥mo los agentes toman decisiones (bucle ReAct)
- [ ] C√≥mo se mide la calidad (m√∫ltiples m√©tricas)
- [ ] C√≥mo se integran los componentes (pipeline)

---

## üî¨ Ideas de Experimentaci√≥n

Intenta modificar:

```python
# 1. Cambiar dimensi√≥n de embedding
EMBEDDING_DIM = 256  # M√°s dimensiones = m√°s preciso

# 2. Cambiar temperatura
temperature = 0.1    # M√°s enfocado
temperature = 2.0    # M√°s creativo

# 3. Cambiar k_documents
k = 5                # M√°s contexto = m√°s lento pero m√°s rico

# 4. A√±adir m√°s documentos
KNOWLEDGE_BASE['doc_4'] = "Tu nuevo documento..."

# 5. Cambiar pesos de evaluaci√≥n
quality_score = (
    length_ratio * 0.1 +
    vocabulary_overlap * 0.5 +  # M√°s √©nfasis aqu√≠
    similarity * 0.2 +
    coherence * 0.2
) * 100
```

---

## üìö Lecturas Adicionales

- **Cap√≠tulo 11:** Temperatura y Generaci√≥n
- **Cap√≠tulo 12:** Razonamiento Chain-of-Thought
- **Cap√≠tulo 13:** Arquitectura RAG
- **Cap√≠tulo 14:** Patrones de Agentes (ReAct)
- **Cap√≠tulo 15:** Evaluaci√≥n

---

**¬°Ahora entiendes el c√≥digo! üéì**
