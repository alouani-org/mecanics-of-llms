# üó∫Ô∏è Recorrido Pedag√≥gico Completo: Libro ‚Üí Scripts ‚Üí Conceptos

> **Gu√≠a completa** para navegar el proyecto "La Mec√°nica de los LLM"  
> Correspondencia detallada: cap√≠tulos del libro ‚Üî scripts Python ‚Üî conceptos pr√°cticos

---

## üìç C√≥mo Empezar...

### Si eres nuevo ‚ú®

```
1. Lee esta p√°gina (est√°s aqu√≠)
   ‚Üì
2. Revisa README.md (navegaci√≥n general)
   ‚Üì
3. Abre PEDAGOGICAL_JOURNEY.md (gu√≠a de scripts)
   ‚Üì
4. Ejecuta tu primer script
```

### Si ya le√≠ste el libro üìñ

```
1. Encuentra tu cap√≠tulo abajo
   ‚Üì
2. Haz clic en el script correspondiente
   ‚Üì
3. Ejecuta y experimenta
```

### Si quieres programar de inmediato üíª

```
1. Ve directamente a: 09_mini_assistant_complet.py
   ‚Üì
2. Lee: INDEX_SCRIPT_09.md (arquitectura)
   ‚Üì
3. Entiende y luego adapta
```

---

## üìö Recorrido Por Cap√≠tulo del Libro

### Cap√≠tulo 1: Introducci√≥n a NLP

**Contenido del Libro:**
- ¬øQu√© es NLP?
- Historia: de reglas a aprendizaje a LLMs
- D√≥nde estamos en 2025

**Enlace de C√≥digo:**
- ‚ùå Sin script dedicado (te√≥rico)
- ‚úÖ Contin√∫a al Cap√≠tulo 2

---

### Cap√≠tulo 2: Representaci√≥n de Texto y Modelos Secuenciales

**Contenido del Libro:**
- ¬øC√≥mo ven los modelos el texto?
- Tokens y tokenizadores (BPE, WordPiece, SentencePiece)
- Impacto en la longitud de secuencia
- RNNs, LSTMs, GRUs (los ancestros)

**üëâ Script Correspondiente:**

#### [`01_tokenization_embeddings.py`](../../01_tokenization_embeddings.py)

**Lo que aprendes ejecutando:**
```python
python 01_tokenization_embeddings.py
```

- Tokenizaci√≥n con diferentes tokenizadores
- Impacto de la tokenizaci√≥n en la longitud de secuencia
- Diferencias Franc√©s vs Ingl√©s
- Embeddings y sus dimensiones
- Costo computacional basado en tokens

**Conceptos Clave Demostrados:**
- Tokenizadores BPE (Byte Pair Encoding)
- Vocabulario y subpalabras
- Relaci√≥n Tokens ‚Üî costo de atenci√≥n O(n¬≤)

**Tiempo de ejecuci√≥n:** ~5 segundos  
**Requisitos:** Python, `transformers`

---

### Cap√≠tulo 3: Arquitectura Transformer

**Contenido del Libro:**
- La invenci√≥n del mecanismo de atenci√≥n
- Self-attention y atenci√≥n multi-cabezas
- Estructura encoder-decoder
- Codificaci√≥n posicional
- El problema de la posici√≥n

**üëâ Script Correspondiente:**

#### [`02_multihead_attention.py`](../../02_multihead_attention.py)

**Lo que aprendes ejecutando:**
```python
python 02_multihead_attention.py
```

- Arquitectura de una capa de atenci√≥n
- Proyecciones Q, K, V (Query, Key, Value)
- C√°lculo de puntuaciones de atenci√≥n
- Multi-head: c√≥mo cada cabeza se enfoca diferente
- Visualizaci√≥n: ¬øqui√©n atiende a qui√©n?

**Conceptos Clave Demostrados:**
- Softmax y normalizaci√≥n de puntuaciones
- Dimensi√≥n de embedding vs n√∫mero de cabezas
- Cada cabeza aprende diferentes relaciones

**Tiempo de ejecuci√≥n:** ~2 segundos  
**Requisitos:** Python, `numpy`

---

### Cap√≠tulos 4-8: Arquitectura, Optimizaci√≥n, Pre-entrenamiento

**Contenido del Libro:**
- Cap. 4: Modelos derivados de Transformer (BERT, GPT, T5...)
- Cap. 5: Optimizaci√≥n de arquitectura (atenci√≥n lineal, RoPE...)
- Cap. 6: Arquitectura MoE (Mixture of Experts)
- Cap. 7: Pre-entrenamiento de LLM
- Cap. 8: Optimizaciones de entrenamiento (acumulaci√≥n de gradiente...)

**Enlace de C√≥digo:**
- üìñ Te√≥rico + conceptos
- ‚ö° Integrado en Script 03 (temperatura durante pre-entrenamiento)
- üèÜ Mejorado en Script 09 (mini-asistente)

---

### Cap√≠tulo 9: Fine-tuning Supervisado (SFT)

**Contenido del Libro:**
- De predicci√≥n a asistencia
- Fine-tuning supervisado (SFT)
- Calidad sobre cantidad
- Evaluaci√≥n de modelos fine-tuneados
- Caso de estudio: adaptar LLaMA 7B

**üëâ Script Bonus Correspondiente:**

#### [`08_lora_finetuning_example.py`](../../08_lora_finetuning_example.py) üéÅ

**Lo que aprendes ejecutando:**
```python
python 08_lora_finetuning_example.py
```

- LoRA (Low-Rank Adaptation)
- QLoRA (Quantized LoRA)
- Comparaci√≥n: full fine-tuning vs LoRA
- Eficiencia en t√©rminos de memoria/velocidad
- Caso real SNCF (del texto del libro)

**Conceptos Clave Demostrados:**
- Adaptar modelos sin reentrenar todo
- Compromiso memoria vs calidad
- Par√°metros adicionales vs ganancia

**Tiempo de ejecuci√≥n:** ~3 segundos  
**Requisitos:** Python, `numpy` (demo sin LLM externo)

---

### Cap√≠tulo 11: Estrategias de Generaci√≥n e Inferencia

**Contenido del Libro:**
- Prompting: guiar el modelo a trav√©s de ejemplos
- Control de temperatura
- Estrategias de muestreo (top-k, top-p, nucleus sampling)
- Optimizar latencia: KV-cache, especulaci√≥n

**üëâ Scripts Correspondientes:**

#### [`03_temperature_softmax.py`](../../03_temperature_softmax.py)

**Lo que aprendes ejecutando:**
```python
python 03_temperature_softmax.py
```

- Efecto de la temperatura en softmax
- T baja = determin√≠stico (greedy)
- T alta = diversidad (creativo)
- Relaci√≥n con la entrop√≠a
- Gr√°ficos del efecto de temperatura

**Conceptos Clave Demostrados:**
- Softmax e interpretaci√≥n probabil√≠stica
- Temperatura como factor de escala
- Compromiso determinismo vs creatividad

**Tiempo de ejecuci√≥n:** ~2 segundos  
**Requisitos:** Python, `matplotlib` (opcional)

#### [`09_mini_assistant_complet.py`](../../09_mini_assistant_complet.py) üèÜ

**Tu primer asistente con:**
- Prompting (Chain-of-Thought)
- Muestreo con temperatura
- Estrategias de generaci√≥n

---

### Cap√≠tulo 12: Modelos de Razonamiento

**Contenido del Libro:**
- Prompting Chain-of-Thought (CoT)
- Tree-of-Thought (ToT)
- C√≥digo y matem√°ticas (demostraci√≥n de razonamiento)
- Aprendizaje por Refuerzo (RL) para pensar

**üëâ Scripts Correspondientes:**

#### [`05_pass_at_k_evaluation.py`](../../05_pass_at_k_evaluation.py)

**Lo que aprendes ejecutando:**
```python
python 05_pass_at_k_evaluation.py
```

- M√©trica Pass@k para evaluaci√≥n
- Pass^k (diferente de Pass@k)
- ¬øPor qu√© estas m√©tricas para razonamiento?
- Emp√≠ricos en tareas de c√≥digo

**Conceptos Clave Demostrados:**
- Evaluaci√≥n m√°s all√° de la simple precisi√≥n
- M√∫ltiples intentos vs un solo intento
- M√©tricas espec√≠ficas para razonamiento

**Tiempo de ejecuci√≥n:** ~1 segundo  
**Requisitos:** Python, `numpy`

---

### Cap√≠tulo 13: Sistemas Aumentados y Agentes (RAG)

**Contenido del Libro:**
- RAG: Retrieval-Augmented Generation
- El problema de integraci√≥n M:N
- Bajo el cap√≥: implementaci√≥n t√©cnica
- Descubrimiento progresivo de herramientas

**üëâ Scripts Correspondientes:**

#### [`04_rag_minimal.py`](../../04_rag_minimal.py)

**Lo que aprendes ejecutando:**
```python
python 04_rag_minimal.py
```

- Pipeline RAG m√≠nimo (entender los pasos)
- Similitud coseno para recuperaci√≥n
- Aumentaci√≥n de contexto
- Calidad vs latencia

**Conceptos Clave Demostrados:**
- Fragmentaci√≥n de documentos (chunking)
- Embeddings y b√∫squeda
- Reducci√≥n de alucinaciones

**Tiempo de ejecuci√≥n:** ~3 segundos  
**Requisitos:** Python, `numpy`, `scikit-learn`

#### [`07_llamaindex_rag_advanced.py`](../../07_llamaindex_rag_advanced.py) üéÅ

**Lo que aprendes ejecutando:**
```python
python 07_llamaindex_rag_advanced.py
```

- Framework RAG completo (LlamaIndex)
- 6 fases: Cargar ‚Üí Indexar ‚Üí RAG ‚Üí Chat ‚Üí Eval ‚Üí Exportar
- Ingesti√≥n de documentos
- Chat con persistencia
- Evaluaci√≥n autom√°tica

**Conceptos Clave Demostrados:**
- Arquitectura RAG de producci√≥n
- Estrategias de indexaci√≥n
- Capa de persistencia

**Tiempo de ejecuci√≥n:** ~5 segundos  
**Requisitos:** Python (demo), opcional: `llama-index`, `openai`

---

### Cap√≠tulo 14: Protocolos Ag√©nticos (MCP)

**Contenido del Libro:**
- Agentes: autonom√≠a y decisi√≥n
- Definici√≥n de agente
- Patrones: ReAct, Tool Use, Function Calling
- Model Context Protocol (MCP)
- Limitaciones y dificultades

**üëâ Script Bonus Correspondiente:**

#### [`06_react_agent_bonus.py`](../../06_react_agent_bonus.py) üéÅ

**Lo que aprendes ejecutando:**
```python
python 06_react_agent_bonus.py
```

- Patr√≥n ReAct (Razonamiento + Acci√≥n)
- Framework gen√©rico para crear agentes
- Registro de herramientas (tool registration)
- 3 herramientas de ejemplo
- Bucle: pensar ‚Üí actuar ‚Üí observar

**Conceptos Clave Demostrados:**
- Bucle de agente aut√≥nomo
- Toma de decisiones
- Composici√≥n de herramientas

**Tiempo de ejecuci√≥n:** ~4 segundos  
**Requisitos:** Python, `numpy`

**Ver tambi√©n:** [REACT_AGENT_INTEGRATION.md](REACT_AGENT_INTEGRATION.md)

---

### Cap√≠tulo 15: Evaluaci√≥n Cr√≠tica de Flujos Ag√©nticos

**Contenido del Libro:**
- El desaf√≠o de la medici√≥n
- Evaluar agentes: de palabras a hechos
- M√©tricas cuantitativas y cualitativas
- Casos de estudio

**üëâ Script Integrador Completo:**

#### [`09_mini_assistant_complet.py`](../../09_mini_assistant_complet.py) üèÜ

**Lo que aprendes ejecutando:**
```python
python 09_mini_assistant_complet.py
```

- Evaluaci√≥n de un sistema completo
- M√©tricas: BLEU, similitud de embeddings, coherencia
- Trazas y debugging
- Mejora iterativa

**Conceptos Clave Demostrados:**
- Evaluaci√≥n multi-criterio
- Bucles de retroalimentaci√≥n
- Calidad de ejecuci√≥n

**Tiempo de ejecuci√≥n:** ~10 segundos  
**Requisitos:** Python (todo incluido)

**Ver tambi√©n:**
- [INDEX_SCRIPT_09.md](INDEX_SCRIPT_09.md) - Arquitectura
- [QUICKSTART_SCRIPT_09.md](QUICKSTART_SCRIPT_09.md) - Inicio r√°pido

**¬°FELICITACIONES!** üéâ ¬°Has completado el recorrido!

---

## üéØ Rutas Aceleradas

### "Quiero entender los LLM r√°pidamente" (2-3 horas)

```
Leer Cap√≠tulos 1-3        (30 min)
   ‚Üì
Ejecutar Scripts 01-02    (15 min)
   ‚Üì
Leer Cap√≠tulos 11-12      (45 min)
   ‚Üì
Ejecutar Scripts 03-05    (30 min)
   ‚Üì
Leer Cap√≠tulos 13-14      (45 min)
   ‚Üì
Ejecutar Script 09        (15 min)
```

**Resultado:** Comprensi√≥n s√≥lida de conceptos clave ‚úÖ

### "Quiero programar una aplicaci√≥n RAG + Agentes" (4-6 horas)

```
Entender RAG              (Cap√≠tulo 13)  (30 min)
   ‚Üì
Ejecutar Scripts 04, 07   (30 min)
   ‚Üì
Entender Agentes          (Cap√≠tulo 14)  (30 min)
   ‚Üì
Ejecutar Script 06        (20 min)
   ‚Üì
Estudiar Script 09        (60 min)
   ‚Üì
Adaptar para tu caso      (variable)
```

**Resultado:** Aplicaci√≥n funcional RAG + Agentes ‚úÖ

---

## üìù Notas

- **No se requiere GPU**: todos los scripts funcionan en CPU (m√°s lento)
- **Dependencias m√≠nimas**: solo `numpy`, `torch`, `transformers`, `scikit-learn`
- **C√≥digo educativo**: prioriza claridad sobre optimizaci√≥n
- **Compatible Python 3.9+**
- **Scripts bonus** demuestran conceptos avanzados, funcionan sin LLM externo (modo simulaci√≥n)

---

**¬°Feliz aprendizaje! üéì**
