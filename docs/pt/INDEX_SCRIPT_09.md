# ðŸ—ï¸ Arquitetura: O Mini Assistente Completo (Script 09)

> **DecomposiÃ§Ã£o completa** do projeto integrador  
> Entendendo a estrutura tÃ©cnica: camadas, componentes, fluxo

---

## ðŸ“ NavegaÃ§Ã£o RÃ¡pida

- **ðŸ“– Ver: [Jornada PedagÃ³gica](PEDAGOGICAL_JOURNEY.md)** - Como se conecta com os capÃ­tulos
- **âš¡ Ver: [InÃ­cio RÃ¡pido](QUICKSTART_SCRIPT_09.md)** - Execute em 5 minutos
- **ðŸ”— Ver: [Mapeamento CÃ³digo â†” Conceitos](SCRIPT_09_MAPPING.md)** - Qual cÃ³digo ensina o quÃª
- **ðŸŒ Outros idiomas: [English](../en/INDEX_SCRIPT_09.md) | [FranÃ§ais](../fr/INDEX_SCRIPT_09.md) | [EspaÃ±ol](../es/INDEX_SCRIPT_09.md)**

---

## ðŸŽ¯ O Que HÃ¡ Dentro?

O Script 09 demonstra TODOS os conceitos dos capÃ­tulos 11-15:

| CapÃ­tulo | Conceito | Componente no Script 09 |
|----------|----------|------------------------|
| 11 | GeraÃ§Ã£o + Temperatura | `generate_with_temperature()` |
| 12 | Chain-of-Thought | `reasoning_phase()` |
| 13 | RAG + RecuperaÃ§Ã£o | `retrieve_documents()` |
| 14 | Agentes ReAct | `agent_loop()` |
| 15 | AvaliaÃ§Ã£o | `evaluate_response()` |

---

## ðŸ—ï¸ Arquitetura TÃ©cnica

### Camada 1: Camada de Dados
```
Base de Conhecimento (em memÃ³ria)
    â†“
FragmentaÃ§Ã£o de Documentos
    â†“
Embeddings Vetoriais (numpy)
```

**Responsabilidade:** Armazenar e indexar conhecimento
**LocalizaÃ§Ã£o do cÃ³digo:** `load_knowledge_base()`, `embed_documents()`

---

### Camada 2: Camada de RecuperaÃ§Ã£o (RAG)
```
Consulta do UsuÃ¡rio
    â†“
Embed da Consulta
    â†“
Busca por Similaridade (cosseno)
    â†“
Contextos Recuperados
```

**Responsabilidade:** Encontrar documentos relevantes
**LocalizaÃ§Ã£o do cÃ³digo:** `retrieve_documents()`

**FunÃ§Ã£o Chave:**
```python
def retrieve_documents(query: str, k: int = 3) -> list:
    # 1. Embed da consulta
    # 2. Calcular similaridade com todos os documentos
    # 3. Retornar top-k mais relevantes
```

---

### Camada 3: Camada de RaciocÃ­nio (Chain-of-Thought)
```
Pergunta
    â†“
Passo 1: Analisar problema
Passo 2: Recuperar contexto
Passo 3: Pensar passo a passo
    â†“
Trace de RaciocÃ­nio
```

**Responsabilidade:** Estruturar o pensamento
**LocalizaÃ§Ã£o do cÃ³digo:** `reasoning_phase()`

---

### Camada 4: Camada de GeraÃ§Ã£o (similar a LLM)
```
Trace de RaciocÃ­nio + Contexto
    â†“
SeleÃ§Ã£o de Token (softmax)
    â†“
Amostragem com Temperatura
    â†“
GeraÃ§Ã£o de Resposta
```

**Responsabilidade:** Criar texto
**LocalizaÃ§Ã£o do cÃ³digo:** `generate_with_temperature()`

---

### Camada 5: Camada de Agente (ReAct)
```
DecisÃ£o do Agente (Pensar)
    â†“
SeleÃ§Ã£o de Ferramenta (Agir)
    â†“
Observar Resultado
    â†“
Loop atÃ© terminar
```

**Responsabilidade:** ExecuÃ§Ã£o autÃ´noma
**LocalizaÃ§Ã£o do cÃ³digo:** `agent_loop()`

---

### Camada 6: Camada de AvaliaÃ§Ã£o
```
Resposta Gerada
    â†“
MÃºltiplas MÃ©tricas (BLEU, Similaridade de Embeddings, CoerÃªncia)
    â†“
PontuaÃ§Ã£o (0-100)
```

**Responsabilidade:** AvaliaÃ§Ã£o de qualidade
**LocalizaÃ§Ã£o do cÃ³digo:** `evaluate_response()`

---

## ðŸ”„ Fluxo de ExecuÃ§Ã£o Completo

```
Entrada do UsuÃ¡rio
    â†“
embed_documents() â†’ Vetores de documentos (128-dim)
    â†“
retrieve_documents() â†’ Top-k documentos similares
    â†“
reasoning_phase() â†’ Pensamento estruturado
    â†“
generate_with_temperature() â†’ GeraÃ§Ã£o de texto
    â†“
agent_loop() â†’ IteraÃ§Ã£o autÃ´noma
    â†“
evaluate_response() â†’ MÃ©tricas de qualidade
    â†“
SaÃ­da para o UsuÃ¡rio
```

**Passo a passo:**

1. **Processamento de Entrada**
   - Parsear consulta do usuÃ¡rio
   - Preparar para recuperaÃ§Ã£o

2. **RecuperaÃ§Ã£o (RAG)**
   - Encontrar contexto relevante da base de conhecimento
   - Retornar top-3 documentos

3. **RaciocÃ­nio**
   - Criar cadeia de pensamento
   - Analisar problema passo a passo
   - Incluir contexto recuperado

4. **GeraÃ§Ã£o**
   - Selecionar tokens usando softmax
   - Aplicar amostragem com temperatura
   - Construir resposta iterativamente

5. **Loop do Agente**
   - Decidir: continuar ou parar?
   - Selecionar ferramenta se necessÃ¡rio
   - Executar e observar

6. **AvaliaÃ§Ã£o**
   - Calcular 5 mÃ©tricas de qualidade
   - Retornar resultado com pontuaÃ§Ã£o

7. **Retorno**
   - Apresentar resposta ao usuÃ¡rio
   - Mostrar mÃ©tricas e trace

---

## ðŸ“¦ FunÃ§Ãµes Principais

### `load_knowledge_base() â†’ dict`
```python
# Retorna dicionÃ¡rio de documentos
{
    'doc_1': "ConteÃºdo sobre IA...",
    'doc_2': "ConteÃºdo sobre LLMs...",
    ...
}
```

---

### `embed_documents(docs: dict) â†’ np.ndarray`
```python
# Retorna matriz (num_docs, embedding_dim)
# Simples: Embeddings baseados em hash para demo
# Real: Usar embeddings do SentenceTransformer
```

---

### `retrieve_documents(query: str, k: int = 3) â†’ list`
```python
# Entrada: "O que Ã© um LLM?"
# SaÃ­da: [
#   {'doc': 'doc_1', 'content': '...', 'similarity': 0.87},
#   {'doc': 'doc_2', 'content': '...', 'similarity': 0.76},
#   {'doc': 'doc_3', 'content': '...', 'similarity': 0.68}
# ]
```

---

### `reasoning_phase(question: str, contexts: list) â†’ str`
```python
# Entrada: pergunta + contextos recuperados
# SaÃ­da: Trace de pensamento estruturado
"""
Passo 1: Analisar a pergunta
O usuÃ¡rio pergunta sobre LLMs...

Passo 2: Identificar conceitos chave
Conceitos: arquitetura, treinamento, inferÃªncia...

Passo 3: Recuperar contexto relevante
Do documento X, sabemos que...

Passo 4: Sintetizar
Combinando o conhecimento, podemos concluir...
"""
```

---

### `generate_with_temperature(prompt: str, temp: float = 1.0) â†’ str`
```python
# Temperatura baixa (0.3): determinÃ­stico, focado
# Temperatura mÃ©dia (1.0): balanceado
# Temperatura alta (2.0): criativo, diverso

# Retorna segmento de texto gerado
```

---

### `agent_loop(initial_query: str, max_turns: int = 3) â†’ dict`
```python
# ExecuÃ§Ã£o agÃªntica
# Cada turno: Pensar â†’ Agir â†’ Observar

# Retorna: {
#   'answer': 'Resposta final',
#   'turns': 3,
#   'trace': ['Turno 1: ...', 'Turno 2: ...', ...]
# }
```

---

### `evaluate_response(response: str, context: str) â†’ dict`
```python
# Calcula 5 mÃ©tricas:
# - Ratio de comprimento
# - SobreposiÃ§Ã£o de vocabulÃ¡rio (BLEU)
# - Similaridade de embeddings
# - PontuaÃ§Ã£o de coerÃªncia
# - Qualidade geral (0-100)

# Retorna: {
#   'metrics': {'bleu': 0.75, 'similarity': 0.82, ...},
#   'quality_score': 79,
#   'interpretation': 'Boa resposta...'
# }
```

---

## âš™ï¸ ConfiguraÃ§Ã£o e ParÃ¢metros

| ParÃ¢metro | Default | Faixa | Efeito |
|-----------|---------|-------|--------|
| `TEMPERATURE` | 1.0 | 0.0-2.0 | Controle de criatividade |
| `K_DOCUMENTS` | 3 | 1-10 | Tamanho do contexto |
| `MAX_TURNS` | 3 | 1-10 | IteraÃ§Ãµes do agente |
| `EMBEDDING_DIM` | 128 | 64-512 | Tamanho do embedding |

**Como modificar:**
```python
# No script 09
TEMPERATURE = 1.5        # Mais criativo
K_DOCUMENTS = 5          # Mais contexto
MAX_TURNS = 5            # Mais iteraÃ§Ãµes do agente
```

---

## ðŸ’¡ Detalhes Chave de ImplementaÃ§Ã£o

### Embeddings (Demo Simplificado)
```python
# ProduÃ§Ã£o real: SentenceTransformer
# VersÃ£o demo: Baseado em hash (determinÃ­stico, rÃ¡pido)

def simple_embedding(text: str, dim: int = 128) -> np.ndarray:
    hash_val = hash(text)
    np.random.seed(abs(hash_val) % 2**32)
    return np.random.randn(dim)
```

---

### Amostragem com Temperatura
```python
# Temperatura = fator de escala para softmax
# logits = [1.0, 2.0, 0.5]
# 
# T=0.5: softmax(logits / 0.5) â†’ mais agudo [0.1, 0.87, 0.03]
# T=1.0: softmax(logits / 1.0) â†’ normal [0.09, 0.67, 0.24]
# T=2.0: softmax(logits / 2.0) â†’ mais plano [0.28, 0.38, 0.34]
```

---

### Prompting Chain-of-Thought
```
Em vez de: "O que Ã© X?"
Melhor:    "Vamos pensar passo a passo:
            1. Definir o conceito
            2. DecompÃ´-lo
            3. Fornecer exemplos
            4. Concluir"
```

---

### ImplementaÃ§Ã£o do Loop ReAct
```python
while not done and turns < max_turns:
    # PENSAR: Analisar estado atual
    thought = analyze_state(context)
    
    # AGIR: Escolher e executar ferramenta/aÃ§Ã£o
    action = select_action(thought)
    result = execute_action(action)
    
    # OBSERVAR: Atualizar conhecimento
    observation = observe_result(result)
    
    turns += 1
```

---

## ðŸŽ¯ Resultados de Aprendizagem

Depois de estudar esta arquitetura, vocÃª entende:

âœ… Como RAG integra recuperaÃ§Ã£o com geraÃ§Ã£o  
âœ… Como a temperatura afeta o comportamento do modelo  
âœ… Como Chain-of-Thought melhora o raciocÃ­nio  
âœ… Como os agentes tomam decisÃµes autÃ´nomas  
âœ… Como avaliar a qualidade de geraÃ§Ã£o  
âœ… Como combinar todos esses conceitos em um sistema  

---

## ðŸš€ PrÃ³ximos Passos

1. **Execute:** [Guia de InÃ­cio RÃ¡pido](QUICKSTART_SCRIPT_09.md)
2. **Entenda o cÃ³digo:** [Mapeamento CÃ³digo â†” Conceitos](SCRIPT_09_MAPPING.md)
3. **Adapte:** Modifique para seu caso de uso
4. **Estenda:** Adicione mais ferramentas, melhores embeddings, etc.

---

**Pronto para aprofundar? ðŸ“š**
