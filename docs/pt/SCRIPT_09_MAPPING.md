# üîó Mapeamento C√≥digo ‚Üî Conceito: Script 09

üåç [English](../en/SCRIPT_09_MAPPING.md) | üìñ [Fran√ßais](../fr/SCRIPT_09_MAPPING.md) | üá™üá∏ [Espa√±ol](../es/SCRIPT_09_MAPPING.md) | üáßüá∑ **Portugu√™s** | üá∏üá¶ [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](../ar/SCRIPT_09_MAPPING.md)

> **Entenda qual c√≥digo implementa qual conceito**  
> Guia de aprendizado linha por linha

---

## üìç Navega√ß√£o R√°pida

- **üìñ Ver: [Jornada Pedag√≥gica](PEDAGOGICAL_JOURNEY.md)** - Teoria
- **üèóÔ∏è Ver: [Arquitetura](INDEX_SCRIPT_09.md)** - Estrutura
- **‚ö° Ver: [In√≠cio R√°pido](QUICKSTART_SCRIPT_09.md)** - Execute
- **üåç Outros idiomas: [English](../en/SCRIPT_09_MAPPING.md) | [Fran√ßais](../fr/SCRIPT_09_MAPPING.md) | [Espa√±ol](../es/SCRIPT_09_MAPPING.md)**

---

## üéØ Se√ß√£o 1: Imports e Setup

### Conceito: Prepara√ß√£o do Ambiente

```python
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from collections import defaultdict
import re
```

**O que ensina:**
- `numpy`: Computa√ß√£o num√©rica (embeddings, softmax)
- `cosine_similarity`: Calcular similaridade entre documentos
- `defaultdict`: Estrutura de dados para base de conhecimento
- `re`: Processamento de texto

---

## üéØ Se√ß√£o 2: Base de Conhecimento

### Conceito: Armazenamento de Dados

```python
KNOWLEDGE_BASE = {
    'doc_1': "Um LLM √© um modelo de linguagem grande...",
    'doc_2': "Transformers usam mecanismos de aten√ß√£o...",
    'doc_3': "RAG combina recupera√ß√£o com gera√ß√£o...",
    # ... mais documentos
}
```

**O que ensina:**
- Como armazenar conhecimento de dom√≠nio
- Estrutura simples de dicion√°rio
- Escal√°vel para milhares de documentos

---

## üéØ Se√ß√£o 3: Embeddings

### Conceito: Texto ‚Üí Representa√ß√£o Vetorial

```python
def create_embedding(text: str, dim: int = 128) -> np.ndarray:
    """Converte texto para vetor usando hash determin√≠stico"""
    hash_val = hash(text)
    np.random.seed(abs(hash_val) % 2**32)
    return np.random.randn(dim)
```

**O que ensina:**
- **Produ√ß√£o real:** Usar SentenceTransformer
  ```python
  from sentence_transformers import SentenceTransformer
  model = SentenceTransformer('all-MiniLM-L6-v2')
  embedding = model.encode(text)
  ```
- **Nesta demo:** Abordagem simplificada baseada em hash para velocidade
- **Conceito chave:** Texto ‚Üí vetor de tamanho fixo (128 dimens√µes)
- **Propriedade:** Texto similar ‚Üí vetores similares

**Analogia do mundo real:**
```
Imagine: Cada documento √© um ponto em espa√ßo de 128 dimens√µes
Pontos pr√≥ximos = significado similar
```

---

## üéØ Se√ß√£o 4: Recupera√ß√£o (RAG Parte 1)

### Conceito: Encontrar Documentos Relevantes

```python
def retrieve_documents(query: str, k: int = 3) -> list:
    """Passo 1: Embed da consulta
       Passo 2: Comparar com todos os documentos
       Passo 3: Retornar top-k mais similares
    """
    query_embedding = create_embedding(query)
    
    # Criar matriz de todos os embeddings de documentos
    doc_embeddings = np.array([
        create_embedding(doc) 
        for doc in KNOWLEDGE_BASE.values()
    ])
    
    # Calcular similaridade cosseno
    similarities = cosine_similarity(
        query_embedding.reshape(1, -1), 
        doc_embeddings
    )[0]
    
    # Obter top-k
    top_indices = np.argsort(similarities)[-k:][::-1]
    
    results = []
    for idx in top_indices:
        doc_name = list(KNOWLEDGE_BASE.keys())[idx]
        results.append({
            'doc': doc_name,
            'content': KNOWLEDGE_BASE[doc_name],
            'similarity': similarities[idx]
        })
    
    return results
```

**O que ensina:**
- **Embedding:** Converter texto para vetor
- **Similaridade:** Similaridade cosseno = qu√£o alinhados est√£o dois vetores?
  ```
  cosine_similarity = (A ¬∑ B) / (||A|| * ||B||)
  Faixa: -1 (oposto) a 1 (id√™ntico)
  ```
- **Sele√ß√£o:** Retornar top-k (mais similares) documentos
- **Complexidade:** O(n*d) onde n=docs, d=dimens√µes

**Analogia do mundo real:**
```
Como um bibliotec√°rio:
1. L√™ sua pergunta
2. Compara mentalmente com todos os livros
3. Traz os 3 livros mais relevantes
```

---

## üéØ Se√ß√£o 5: Racioc√≠nio (Chain-of-Thought)

### Conceito: Resolu√ß√£o Estruturada de Problemas

```python
def reasoning_phase(question: str, contexts: list) -> str:
    """Pensa passo a passo com contexto recuperado"""
    
    reasoning = f"""
    Passo 1: Analisar a Pergunta
    O usu√°rio pergunta sobre: {question}
    
    Passo 2: Conceitos Chave
    Extrair conceitos principais da pergunta
    
    Passo 3: Recuperar Contexto Relevante
    Dos documentos recuperados:
    """
    
    for i, ctx in enumerate(contexts, 1):
        reasoning += f"\n- De {ctx['doc']}: {ctx['content'][:100]}..."
    
    reasoning += f"""
    
    Passo 4: Sintetizar uma Resposta
    Combinando o conhecimento:
    - Ponto 1: [do contexto 1]
    - Ponto 2: [do contexto 2]
    - Ponto 3: [do contexto 3]
    
    Conclus√£o: Baseado no acima, podemos concluir...
    """
    
    return reasoning
```

**O que ensina:**
- **Chain-of-Thought:** Dividir problema em passos
- **Integra√ß√£o de Contexto:** Usar documentos recuperados
- **Reprodutibilidade:** Cada passo √© vis√≠vel
- **Transpar√™ncia:** F√°cil de debugar o racioc√≠nio

**Analogia do mundo real:**
```
Como mostrar seu trabalho em matem√°tica:
N√£o apenas "resposta: 42"
Mas "Passo 1: ... Passo 2: ... Passo 3: ... Resposta: 42"
```

---

## üéØ Se√ß√£o 6: Gera√ß√£o com Temperatura

### Conceito: Softmax e Amostragem com Temperatura

```python
def generate_with_temperature(
    prompt: str, 
    temperature: float = 1.0
) -> str:
    """
    Simula gera√ß√£o de tokens com controle de temperatura
    
    Temperatura:
    - 0.1: Muito focado (determin√≠stico)
    - 1.0: Balanceado (softmax normal)
    - 2.0: Muito criativo (diverso)
    """
    
    # Simular logits (pontua√ß√µes n√£o normalizadas)
    prompt_hash = hash(prompt)
    np.random.seed(abs(prompt_hash) % 2**32)
    logits = np.random.randn(100) * 2
    
    # Aplicar escala de temperatura
    scaled_logits = logits / temperature
    
    # Softmax para obter probabilidades
    exp_logits = np.exp(scaled_logits - np.max(scaled_logits))
    probabilities = exp_logits / np.sum(exp_logits)
    
    # Amostrar token
    selected_idx = np.random.choice(100, p=probabilities)
    
    # Gerar texto
    vocab = ["um", "LLM", "√©", "um", "modelo", "que", 
             "gera", "texto", "usando", "redes", "neurais"]
    response = " ".join([vocab[i % len(vocab)] for i in range(selected_idx % 20)])
    
    return response
```

**O que ensina:**

**F√≥rmula Softmax:**
```
softmax(x_i) = exp(x_i) / sum(exp(x_j))
Resultado: distribui√ß√£o de probabilidade (soma = 1)
```

**Efeito da Temperatura:**
```
T = 0.1  ‚Üí  [0.01, 0.98, 0.01]  ‚Üê Agudo (determin√≠stico)
T = 1.0  ‚Üí  [0.15, 0.70, 0.15]  ‚Üê Balanceado
T = 2.0  ‚Üí  [0.30, 0.40, 0.30]  ‚Üê Plano (diverso)
```

**Insight chave:**
- T baixa: O modelo repete o token mais prov√°vel (chato)
- T alta: O modelo explora alternativas (criativo)

---

## üéØ Se√ß√£o 7: Loop do Agente (ReAct)

### Conceito: Tomada de Decis√£o Aut√¥noma

```python
def agent_loop(
    initial_query: str, 
    max_turns: int = 3
) -> dict:
    """
    Padr√£o ReAct:
    PENSAR ‚Üí AGIR ‚Üí OBSERVAR ‚Üí (repetir)
    """
    
    context = initial_query
    trace = []
    turn = 0
    
    while turn < max_turns:
        turn += 1
        
        # PENSAR: Analisar estado atual
        thought = f"Turno {turn}: Analisando '{context[:50]}...'"
        trace.append(f"PENSAR: {thought}")
        
        # Decidir: Continuar ou Parar?
        should_continue = turn < max_turns and len(context) < 500
        
        if not should_continue:
            trace.append("PARAR: Informa√ß√£o suficiente coletada")
            break
        
        # AGIR: Recuperar documentos
        documents = retrieve_documents(context, k=2)
        trace.append(f"AGIR: Recuperados {len(documents)} documentos")
        
        # OBSERVAR: Processar resultados
        context += f" [Recuperado: {documents[0]['doc']}]"
        trace.append(f"OBSERVAR: Adicionado contexto de {documents[0]['doc']}")
    
    return {
        'answer': context,
        'turns': turn,
        'trace': trace
    }
```

**O que ensina:**

**Loop ReAct:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PENSAR (analisar estado)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ AGIR (tomar a√ß√£o/recuperar)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ OBSERVAR (processar resultados) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
        Repetir ou Parar?
```

**Propriedades chave:**
- Aut√¥nomo: Toma decis√µes independentemente
- Observ√°vel: Cada passo √© rastreado
- Iterativo: Melhora a cada turno
- Par√°vel: Sabe quando parar

---

## üéØ Se√ß√£o 8: M√©tricas de Avalia√ß√£o

### Conceito: Avalia√ß√£o de Qualidade

```python
def evaluate_response(response: str, context: str) -> dict:
    """Calcula m√∫ltiplas m√©tricas de qualidade"""
    
    # M√©trica 1: Ratio de Comprimento
    length_ratio = min(len(response), 500) / 500
    
    # M√©trica 2: BLEU-like (sobreposi√ß√£o de vocabul√°rio)
    response_words = set(response.lower().split())
    context_words = set(context.lower().split())
    overlap = len(response_words & context_words)
    vocabulary_overlap = overlap / max(len(response_words), 1)
    
    # M√©trica 3: Similaridade de Embeddings
    response_emb = create_embedding(response)
    context_emb = create_embedding(context)
    similarity = cosine_similarity(
        response_emb.reshape(1, -1),
        context_emb.reshape(1, -1)
    )[0][0]
    
    # M√©trica 4: Coer√™ncia (diversidade de tokens)
    tokens = response.lower().split()
    unique_ratio = len(set(tokens)) / max(len(tokens), 1)
    coherence = 0.5 + 0.5 * (1 - unique_ratio)  # Balanceado
    
    # M√©trica 5: Qualidade Geral
    quality_score = (
        length_ratio * 0.2 +
        vocabulary_overlap * 0.3 +
        similarity * 0.25 +
        coherence * 0.25
    ) * 100
    
    return {
        'metrics': {
            'length_ratio': length_ratio,
            'vocabulary_overlap': vocabulary_overlap,
            'embedding_similarity': similarity,
            'coherence': coherence
        },
        'quality_score': quality_score,
        'interpretation': interpret_score(quality_score)
    }
```

**O que ensina:**

**Tipos de M√©tricas:**

1. **Ratio de Comprimento**: 0-1
   - Garante que a resposta n√£o seja muito curta/longa
   
2. **BLEU Score**: 0-1
   - Quantas palavras se sobrep√µem com o contexto?
   
3. **Similaridade de Embeddings**: -1 a 1
   - Resposta e contexto s√£o semanticamente similares?
   
4. **Coer√™ncia**: 0-1
   - A resposta evita repeti√ß√£o?
   
5. **Qualidade Geral**: 0-100
   - Combina√ß√£o ponderada das anteriores

**Por que m√∫ltiplas m√©tricas?**
```
Uma √∫nica m√©trica = imagem incompleta
Exemplo: Uma resposta curta e gen√©rica pode pontuar alto em 
         vocabulary_overlap mas baixo em length_ratio
```

---

## üéì Lista de Verifica√ß√£o de Aprendizado

Depois de ler isso, voc√™ deve entender:

- [ ] Como texto se torna vetores (embeddings)
- [ ] Como a similaridade √© calculada (similaridade cosseno)
- [ ] Como documentos s√£o recuperados (busca k-NN)
- [ ] Como o racioc√≠nio √© estruturado (Chain-of-Thought)
- [ ] Como a temperatura afeta a aleatoriedade (escala softmax)
- [ ] Como agentes tomam decis√µes (loop ReAct)
- [ ] Como a qualidade √© medida (m√∫ltiplas m√©tricas)
- [ ] Como componentes se integram (pipeline)

---

## üî¨ Ideias de Experimenta√ß√£o

Tente modificar:

```python
# 1. Mudar dimens√£o de embedding
EMBEDDING_DIM = 256  # Mais dimens√µes = mais preciso

# 2. Mudar temperatura
temperature = 0.1    # Mais focado
temperature = 2.0    # Mais criativo

# 3. Mudar k_documents
k = 5                # Mais contexto = mais lento mas mais rico

# 4. Adicionar mais documentos
KNOWLEDGE_BASE['doc_4'] = "Seu novo documento..."

# 5. Mudar pesos de avalia√ß√£o
quality_score = (
    length_ratio * 0.1 +
    vocabulary_overlap * 0.5 +  # Mais √™nfase aqui
    similarity * 0.2 +
    coherence * 0.2
) * 100
```

---

## üìö Leituras Adicionais

- **Cap√≠tulo 11:** Temperatura e Gera√ß√£o
- **Cap√≠tulo 12:** Racioc√≠nio Chain-of-Thought
- **Cap√≠tulo 13:** Arquitetura RAG
- **Cap√≠tulo 14:** Padr√µes de Agentes (ReAct)
- **Cap√≠tulo 15:** Avalia√ß√£o

---

**Agora voc√™ entende o c√≥digo! üéì**
