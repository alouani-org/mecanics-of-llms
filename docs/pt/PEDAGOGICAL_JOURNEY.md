# ğŸ—ºï¸ Jornada PedagÃ³gica Completa: Livro â†’ Scripts â†’ Conceitos

ğŸŒ [English](../en/PEDAGOGICAL_JOURNEY.md) | ğŸ“– [FranÃ§ais](../fr/PEDAGOGICAL_JOURNEY.md) | ğŸ‡ªğŸ‡¸ [EspaÃ±ol](../es/PEDAGOGICAL_JOURNEY.md) | ğŸ‡§ğŸ‡· **PortuguÃªs** | ğŸ‡¸ğŸ‡¦ [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](../ar/PEDAGOGICAL_JOURNEY.md)

> **Guia completo** para navegar o projeto "A MecÃ¢nica dos LLMs"  
> CorrespondÃªncia detalhada: capÃ­tulos do livro â†” scripts Python â†” conceitos prÃ¡ticos

---

## ğŸ“ Como ComeÃ§ar...

### Se vocÃª Ã© novo âœ¨

```
1. Leia esta pÃ¡gina (vocÃª estÃ¡ aqui)
   â†“
2. Confira README.md (navegaÃ§Ã£o geral)
   â†“
3. Abra PEDAGOGICAL_JOURNEY.md (guia de scripts)
   â†“
4. Execute seu primeiro script
```

### Se vocÃª jÃ¡ leu o livro ğŸ“–

```
1. Encontre seu capÃ­tulo abaixo
   â†“
2. Clique no script correspondente
   â†“
3. Execute e experimente
```

### Se vocÃª quer programar imediatamente ğŸ’»

```
1. VÃ¡ direto para: 09_mini_assistant_complet.py
   â†“
2. Leia: INDEX_SCRIPT_09.md (arquitetura)
   â†“
3. Entenda e depois adapte
```

---

## ğŸ“š Jornada Por CapÃ­tulo do Livro

### CapÃ­tulo 1: IntroduÃ§Ã£o a NLP

**ConteÃºdo do Livro:**
- O que Ã© NLP?
- HistÃ³ria: de regras para aprendizado para LLMs
- Onde estamos em 2025

**Link de CÃ³digo:**
- âŒ Sem script dedicado (teÃ³rico)
- âœ… Continue para o CapÃ­tulo 2

---

### CapÃ­tulo 2: RepresentaÃ§Ã£o de Texto e Modelos Sequenciais

**ConteÃºdo do Livro:**
- Como os modelos veem o texto?
- Tokens e tokenizadores (BPE, WordPiece, SentencePiece)
- Impacto no comprimento da sequÃªncia
- RNNs, LSTMs, GRUs (os ancestrais)

**ğŸ‘‰ Script Correspondente:**

#### [`01_tokenization_embeddings.py`](../../01_tokenization_embeddings.py)

**O que vocÃª aprende executando:**
```python
python 01_tokenization_embeddings.py
```

- TokenizaÃ§Ã£o com diferentes tokenizadores
- Impacto da tokenizaÃ§Ã£o no comprimento da sequÃªncia
- DiferenÃ§as FrancÃªs vs InglÃªs
- Embeddings e suas dimensÃµes
- Custo computacional baseado em tokens

**Conceitos Chave Demonstrados:**
- Tokenizadores BPE (Byte Pair Encoding)
- VocabulÃ¡rio e subpalavras
- RelaÃ§Ã£o Tokens â†” custo de atenÃ§Ã£o O(nÂ²)

**Tempo de execuÃ§Ã£o:** ~5 segundos  
**Requisitos:** Python, `transformers`

---

### CapÃ­tulo 3: Arquitetura Transformer

**ConteÃºdo do Livro:**
- A invenÃ§Ã£o do mecanismo de atenÃ§Ã£o
- Self-attention e atenÃ§Ã£o multi-cabeÃ§as
- Estrutura encoder-decoder
- CodificaÃ§Ã£o posicional
- O problema da posiÃ§Ã£o

**ğŸ‘‰ Script Correspondente:**

#### [`02_multihead_attention.py`](../../02_multihead_attention.py)

**O que vocÃª aprende executando:**
```python
python 02_multihead_attention.py
```

- Arquitetura de uma camada de atenÃ§Ã£o
- ProjeÃ§Ãµes Q, K, V (Query, Key, Value)
- CÃ¡lculo de pontuaÃ§Ãµes de atenÃ§Ã£o
- Multi-head: como cada cabeÃ§a foca diferente
- VisualizaÃ§Ã£o: quem atende a quem?

**Conceitos Chave Demonstrados:**
- Softmax e normalizaÃ§Ã£o de pontuaÃ§Ãµes
- DimensÃ£o de embedding vs nÃºmero de cabeÃ§as
- Cada cabeÃ§a aprende diferentes relaÃ§Ãµes

**Tempo de execuÃ§Ã£o:** ~2 segundos  
**Requisitos:** Python, `numpy`

---

### CapÃ­tulos 4-8: Arquitetura, OtimizaÃ§Ã£o, PrÃ©-treinamento

**ConteÃºdo do Livro:**
- Cap. 4: Modelos derivados do Transformer (BERT, GPT, T5...)
- Cap. 5: OtimizaÃ§Ã£o de arquitetura (atenÃ§Ã£o linear, RoPE...)
- Cap. 6: Arquitetura MoE (Mixture of Experts)
- Cap. 7: PrÃ©-treinamento de LLM
- Cap. 8: OtimizaÃ§Ãµes de treinamento (acumulaÃ§Ã£o de gradiente...)

**Link de CÃ³digo:**
- ğŸ“– TeÃ³rico + conceitos
- âš¡ Integrado no Script 03 (temperatura durante prÃ©-treinamento)
- ğŸ† Aprimorado no Script 09 (mini-assistente)

---

### CapÃ­tulo 9: Fine-tuning Supervisionado (SFT)

**ConteÃºdo do Livro:**
- De prediÃ§Ã£o para assistÃªncia
- Fine-tuning supervisionado (SFT)
- Qualidade sobre quantidade
- AvaliaÃ§Ã£o de modelos fine-tunados
- Estudo de caso: adaptar LLaMA 7B

**ğŸ‘‰ Script BÃ´nus Correspondente:**

#### [`08_lora_finetuning_example.py`](../../08_lora_finetuning_example.py) ğŸ

**O que vocÃª aprende executando:**
```python
python 08_lora_finetuning_example.py
```

- LoRA (Low-Rank Adaptation)
- QLoRA (Quantized LoRA)
- ComparaÃ§Ã£o: full fine-tuning vs LoRA
- EficiÃªncia em termos de memÃ³ria/velocidade
- Caso real SNCF (do texto do livro)

**Conceitos Chave Demonstrados:**
- Adaptar modelos sem retreinar tudo
- Tradeoff memÃ³ria vs qualidade
- ParÃ¢metros adicionais vs ganho

**Tempo de execuÃ§Ã£o:** ~3 segundos  
**Requisitos:** Python, `numpy` (demo sem LLM externo)

---

### CapÃ­tulo 11: EstratÃ©gias de GeraÃ§Ã£o e InferÃªncia

**ConteÃºdo do Livro:**
- Prompting: guiar o modelo atravÃ©s de exemplos
- Controle de temperatura
- EstratÃ©gias de amostragem (top-k, top-p, nucleus sampling)
- Otimizar latÃªncia: KV-cache, especulaÃ§Ã£o

**ğŸ‘‰ Scripts Correspondentes:**

#### [`03_temperature_softmax.py`](../../03_temperature_softmax.py)

**O que vocÃª aprende executando:**
```python
python 03_temperature_softmax.py
```

- Efeito da temperatura no softmax
- T baixa = determinÃ­stico (greedy)
- T alta = diversidade (criativo)
- RelaÃ§Ã£o com entropia
- GrÃ¡ficos do efeito de temperatura

**Conceitos Chave Demonstrados:**
- Softmax e interpretaÃ§Ã£o probabilÃ­stica
- Temperatura como fator de escala
- Tradeoff determinismo vs criatividade

**Tempo de execuÃ§Ã£o:** ~2 segundos  
**Requisitos:** Python, `matplotlib` (opcional)

#### [`09_mini_assistant_complet.py`](../../09_mini_assistant_complet.py) ğŸ†

**Seu primeiro assistente com:**
- Prompting (Chain-of-Thought)
- Amostragem com temperatura
- EstratÃ©gias de geraÃ§Ã£o

---

### CapÃ­tulo 12: Modelos de RaciocÃ­nio

**ConteÃºdo do Livro:**
- Prompting Chain-of-Thought (CoT)
- Tree-of-Thought (ToT)
- CÃ³digo e matemÃ¡tica (demonstraÃ§Ã£o de raciocÃ­nio)
- Aprendizado por ReforÃ§o (RL) para pensar

**ğŸ‘‰ Scripts Correspondentes:**

#### [`05_pass_at_k_evaluation.py`](../../05_pass_at_k_evaluation.py)

**O que vocÃª aprende executando:**
```python
python 05_pass_at_k_evaluation.py
```

- MÃ©trica Pass@k para avaliaÃ§Ã£o
- Pass^k (diferente de Pass@k)
- Por que essas mÃ©tricas para raciocÃ­nio?
- EmpÃ­ricos em tarefas de cÃ³digo

**Conceitos Chave Demonstrados:**
- AvaliaÃ§Ã£o alÃ©m da simples acurÃ¡cia
- MÃºltiplas tentativas vs Ãºnica tentativa
- MÃ©tricas especÃ­ficas para raciocÃ­nio

**Tempo de execuÃ§Ã£o:** ~1 segundo  
**Requisitos:** Python, `numpy`

---

### CapÃ­tulo 13: Sistemas Aumentados e Agentes (RAG)

**ConteÃºdo do Livro:**
- RAG: Retrieval-Augmented Generation
- O problema de integraÃ§Ã£o M:N
- Por baixo do capÃ´: implementaÃ§Ã£o tÃ©cnica
- Descoberta progressiva de ferramentas

**ğŸ‘‰ Scripts Correspondentes:**

#### [`04_rag_minimal.py`](../../04_rag_minimal.py)

**O que vocÃª aprende executando:**
```python
python 04_rag_minimal.py
```

- Pipeline RAG mÃ­nimo (entender os passos)
- Similaridade cosseno para recuperaÃ§Ã£o
- AumentaÃ§Ã£o de contexto
- Qualidade vs latÃªncia

**Conceitos Chave Demonstrados:**
- FragmentaÃ§Ã£o de documentos (chunking)
- Embeddings e busca
- ReduÃ§Ã£o de alucinaÃ§Ãµes

**Tempo de execuÃ§Ã£o:** ~3 segundos  
**Requisitos:** Python, `numpy`, `scikit-learn`

#### [`07_llamaindex_rag_advanced.py`](../../07_llamaindex_rag_advanced.py) ğŸ

**O que vocÃª aprende executando:**
```python
python 07_llamaindex_rag_advanced.py
```

- Framework RAG completo (LlamaIndex)
- 6 fases: Carregar â†’ Indexar â†’ RAG â†’ Chat â†’ Eval â†’ Exportar
- IngestÃ£o de documentos
- Chat com persistÃªncia
- AvaliaÃ§Ã£o automÃ¡tica

**Conceitos Chave Demonstrados:**
- Arquitetura RAG de produÃ§Ã£o
- EstratÃ©gias de indexaÃ§Ã£o
- Camada de persistÃªncia

**Tempo de execuÃ§Ã£o:** ~5 segundos  
**Requisitos:** Python (demo), opcional: `llama-index`, `openai`

---

### CapÃ­tulo 14: Protocolos AgÃªnticos (MCP)

**ConteÃºdo do Livro:**
- Agentes: autonomia e decisÃ£o
- DefiniÃ§Ã£o de agente
- PadrÃµes: ReAct, Tool Use, Function Calling
- Model Context Protocol (MCP)
- LimitaÃ§Ãµes e dificuldades

**ğŸ‘‰ Script BÃ´nus Correspondente:**

#### [`06_react_agent_bonus.py`](../../06_react_agent_bonus.py) ğŸ

**O que vocÃª aprende executando:**
```python
python 06_react_agent_bonus.py
```

- PadrÃ£o ReAct (RaciocÃ­nio + AÃ§Ã£o)
- Framework genÃ©rico para criar agentes
- Registro de ferramentas (tool registration)
- 3 ferramentas de exemplo
- Loop: pensar â†’ agir â†’ observar

**Conceitos Chave Demonstrados:**
- Loop de agente autÃ´nomo
- Tomada de decisÃµes
- ComposiÃ§Ã£o de ferramentas

**Tempo de execuÃ§Ã£o:** ~4 segundos  
**Requisitos:** Python, `numpy`

**Veja tambÃ©m:** [REACT_AGENT_INTEGRATION.md](REACT_AGENT_INTEGRATION.md)

---

### CapÃ­tulo 15: AvaliaÃ§Ã£o CrÃ­tica de Fluxos AgÃªnticos

**ConteÃºdo do Livro:**
- O desafio da mediÃ§Ã£o
- Avaliar agentes: de palavras para fatos
- MÃ©tricas quantitativas e qualitativas
- Estudos de caso

**ğŸ‘‰ Script Integrador Completo:**

#### [`09_mini_assistant_complet.py`](../../09_mini_assistant_complet.py) ğŸ†

**O que vocÃª aprende executando:**
```python
python 09_mini_assistant_complet.py
```

- AvaliaÃ§Ã£o de um sistema completo
- MÃ©tricas: BLEU, similaridade de embeddings, coerÃªncia
- Traces e debugging
- Melhoria iterativa

**Conceitos Chave Demonstrados:**
- AvaliaÃ§Ã£o multi-critÃ©rio
- Loops de feedback
- Qualidade de execuÃ§Ã£o

**Tempo de execuÃ§Ã£o:** ~10 segundos  
**Requisitos:** Python (tudo incluÃ­do)

**Veja tambÃ©m:**
- [INDEX_SCRIPT_09.md](INDEX_SCRIPT_09.md) - Arquitetura
- [QUICKSTART_SCRIPT_09.md](QUICKSTART_SCRIPT_09.md) - InÃ­cio rÃ¡pido

**PARABÃ‰NS!** ğŸ‰ VocÃª completou a jornada!

---

## ğŸ¯ Rotas Aceleradas

### "Quero entender LLMs rapidamente" (2-3 horas)

```
Ler CapÃ­tulos 1-3         (30 min)
   â†“
Executar Scripts 01-02    (15 min)
   â†“
Ler CapÃ­tulos 11-12       (45 min)
   â†“
Executar Scripts 03-05    (30 min)
   â†“
Ler CapÃ­tulos 13-14       (45 min)
   â†“
Executar Script 09        (15 min)
```

**Resultado:** CompreensÃ£o sÃ³lida dos conceitos chave âœ…

### "Quero programar uma aplicaÃ§Ã£o RAG + Agentes" (4-6 horas)

```
Entender RAG              (CapÃ­tulo 13)  (30 min)
   â†“
Executar Scripts 04, 07   (30 min)
   â†“
Entender Agentes          (CapÃ­tulo 14)  (30 min)
   â†“
Executar Script 06        (20 min)
   â†“
Estudar Script 09         (60 min)
   â†“
Adaptar para seu caso     (variÃ¡vel)
```

**Resultado:** AplicaÃ§Ã£o funcional RAG + Agentes âœ…

---

## ğŸ“ Notas

- **GPU nÃ£o Ã© necessÃ¡rio**: todos os scripts funcionam em CPU (mais lento)
- **DependÃªncias mÃ­nimas**: apenas `numpy`, `torch`, `transformers`, `scikit-learn`
- **CÃ³digo educativo**: prioriza clareza sobre otimizaÃ§Ã£o
- **CompatÃ­vel Python 3.9+**
- **Scripts bÃ´nus** demonstram conceitos avanÃ§ados, funcionam sem LLM externo (modo simulaÃ§Ã£o)

---

**Bom aprendizado! ğŸ“**
