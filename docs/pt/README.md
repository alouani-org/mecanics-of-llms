# Scripts PrÃ¡ticos: Experimentando com Conceitos de LLM

ğŸŒ [English](../en/README.md) | ğŸ“– [FranÃ§ais](../fr/README.md) | ğŸ‡ªğŸ‡¸ [EspaÃ±ol](../es/README.md) | ğŸ‡§ğŸ‡· **PortuguÃªs** | ğŸ‡¸ğŸ‡¦ [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](../ar/README.md)

ColeÃ§Ã£o de **10 scripts Python executÃ¡veis** para experimentar os conceitos-chave do livro **"A MecÃ¢nica dos LLMs"**.

> ğŸ“š **Sobre**: Estes scripts acompanham os capÃ­tulos do livro. Veja [Jornada PedagÃ³gica](PEDAGOGICAL_JOURNEY.md) para as correspondÃªncias detalhadas.

**ğŸ“• Comprar o Livro:**
- **Impresso**: [Amazon](https://amzn.eu/d/3oREERI)
- **Kindle**: [Amazon](https://amzn.eu/d/b7sG5iw)

---

## ğŸ“‹ VisÃ£o Geral dos Scripts

| # | Script | CapÃ­tulo(s) | Conceitos | Status |
|---|--------|-------------|-----------|--------|
| 1 | `01_tokenization_embeddings.py` | 2 | TokenizaÃ§Ã£o, impacto no comprimento da sequÃªncia | âœ… |
| 2 | `02_multihead_attention.py` | 3 | Self-attention, multi-head, pesos de atenÃ§Ã£o | âœ… |
| 3 | `03_temperature_softmax.py` | 7, 11 | Temperatura, softmax, entropia | âœ… |
| 4 | `04_rag_minimal.py` | 13 | Pipeline RAG, recuperaÃ§Ã£o, similaridade cosseno | âœ… |
| 5 | `05_pass_at_k_evaluation.py` | 12 | Pass@k, Pass^k, avaliaÃ§Ã£o de modelos | âœ… |
| ğŸ 6 | `06_react_agent_bonus.py` | 14, 15 | **Agentes ReAct, registro de ferramentas, MCP** | âœ… BÃ”NUS |
| ğŸ 7 | `07_llamaindex_rag_advanced.py` | 13, 14 | **RAG avanÃ§ado, indexaÃ§Ã£o, chat persistente** | âœ… BÃ”NUS |
| ğŸ 8 | `08_lora_finetuning_example.py` | 9, 10 | **LoRA, QLoRA, comparaÃ§Ã£o de fine-tuning** | âœ… BÃ”NUS |
| ğŸ† **9** | `09_mini_assistant_complet.py` | **11-15** | **ğŸ¯ Projeto Integrador Final** | âœ… PRINCIPAL |
| ğŸ 10 | `10_activation_steering_demo.py` | 10 | **Activation Steering, 3SO, vetores de conceito** | âœ… BÃ”NUS |

---

## ğŸ“– DescriÃ§Ãµes Detalhadas dos Scripts

### ğŸ“Œ Script 01: TokenizaÃ§Ã£o e Embeddings
**Arquivo:** `01_tokenization_embeddings.py` | **CapÃ­tulo:** 2

**O que o script faz:**
- Carrega um tokenizador (GPT-2 ou LLaMA-2) e analisa diferentes textos
- Compara o nÃºmero de tokens entre francÃªs e inglÃªs
- Demonstra o impacto do comprimento da sequÃªncia no custo computacional

**O que vocÃª aprende:**
- Como o texto Ã© dividido em tokens (BPE, WordPiece)
- Por que "Bonjour" pode virar 2-3 tokens enquanto "Hello" Ã© apenas um
- O impacto direto: mais tokens = maior custo O(nÂ²) para atenÃ§Ã£o

**SaÃ­da esperada:**
```
Text: L'IA est utile
  Token count: 5
  Tokens: ['L', "'", 'IA', 'est', 'utile']
```

---

### ğŸ“Œ Script 02: AtenÃ§Ã£o Multi-CabeÃ§as
**Arquivo:** `02_multihead_attention.py` | **CapÃ­tulo:** 3

**O que o script faz:**
- Simula uma camada de atenÃ§Ã£o multi-cabeÃ§as com tensores PyTorch
- Calcula as projeÃ§Ãµes Q, K, V e os pesos de atenÃ§Ã£o
- Mostra como cada cabeÃ§a "olha" a frase de maneira diferente

**O que vocÃª aprende:**
- O mecanismo Q (Query), K (Key), V (Value)
- Por que mÃºltiplas cabeÃ§as capturam diferentes dependÃªncias
- Que os pesos de atenÃ§Ã£o sempre somam 1 (distribuiÃ§Ã£o de probabilidade)

**SaÃ­da esperada:**
```
Sentence: The cat sleeps well
Head 1: Attention weights from 'cat' â†’ 'sleeps': 0.42
Head 2: Attention weights from 'cat' â†’ 'The': 0.38
```

---

### ğŸ“Œ Script 03: Temperatura e Softmax
**Arquivo:** `03_temperature_softmax.py` | **CapÃ­tulos:** 7, 11

**O que o script faz:**
- Aplica softmax com diferentes temperaturas (0.1, 0.5, 1.0, 2.0)
- Calcula a entropia de Shannon para cada distribuiÃ§Ã£o
- Gera grÃ¡ficos (se matplotlib estiver instalado)

**O que vocÃª aprende:**
- T < 1: distribuiÃ§Ã£o "aguda" â†’ geraÃ§Ã£o determinÃ­stica (greedy)
- T > 1: distribuiÃ§Ã£o "plana" â†’ geraÃ§Ã£o criativa/diversa
- A entropia aumenta com a temperatura (mais incerteza)

**SaÃ­da esperada:**
```
Temperature 0.5: Token 'Paris' = 85% (agudo, determinÃ­stico)
Temperature 2.0: Token 'Paris' = 35% (plano, criativo)
```

---

### ğŸ“Œ Script 04: RAG MÃ­nimo
**Arquivo:** `04_rag_minimal.py` | **CapÃ­tulo:** 13

**O que o script faz:**
- Cria uma mini base de conhecimento (7 documentos sobre LLMs)
- Vetoriza os documentos com TF-IDF
- Realiza busca por similaridade cosseno
- Simula a geraÃ§Ã£o aumentada pelo contexto recuperado

**O que vocÃª aprende:**
- O pipeline RAG completo: RecuperaÃ§Ã£o â†’ AumentaÃ§Ã£o â†’ GeraÃ§Ã£o
- Como a similaridade cosseno encontra os documentos relevantes
- Por que RAG permite responder perguntas sobre dados privados

**SaÃ­da esperada:**
```
Pergunta: "Como funciona a atenÃ§Ã£o no Transformer?"
â†’ Documentos recuperados: [doc_1: 0.72, doc_4: 0.65]
â†’ Resposta gerada com contexto
```

---

### ğŸ“Œ Script 05: AvaliaÃ§Ã£o Pass@k
**Arquivo:** `05_pass_at_k_evaluation.py` | **CapÃ­tulo:** 12

**O que o script faz:**
- Simula 100 tentativas de geraÃ§Ã£o com taxa de sucesso de 30%
- Calcula Pass@k (pelo menos 1 sucesso em k tentativas)
- Calcula Pass^k (todas as k tentativas bem-sucedidas)

**O que vocÃª aprende:**
- Pass@k = 1 - (1-p)^k: probabilidade de pelo menos um sucesso
- Pass^k = p^k: probabilidade de todos terem sucesso (muito rigoroso)
- Por que Pass@10 â‰ˆ 97% mesmo com p=30% (vocÃª tem 10 chances)

**SaÃ­da esperada:**
```
Pass@1  = 30%  (chance com 1 tentativa)
Pass@5  = 83%  (chance com 5 tentativas)
Pass@10 = 97%  (quase certo com 10 tentativas)
```

---

### ğŸ Script 06: Agente ReAct (BÃ”NUS)
**Arquivo:** `06_react_agent_bonus.py` | **CapÃ­tulos:** 14, 15

**O que o script faz:**
- Implementa um mini framework de agentes autÃ´nomos
- Demonstra o loop ReAct: Thought â†’ Action â†’ Observation â†’ ...
- Inclui ferramentas simuladas: calculadora, busca web, clima

**O que vocÃª aprende:**
- O padrÃ£o ReAct (RaciocÃ­nio + AÃ§Ã£o)
- Como um agente decide qual aÃ§Ã£o tomar
- Auto-correÃ§Ã£o: o agente pode tentar novamente se uma aÃ§Ã£o falhar
- A base para entender agentes MCP (Model Context Protocol)

**SaÃ­da esperada:**
```
Thought: Preciso calcular 15% de R$250
Action: calculator(250 * 0.15)
Observation: 37.5
Final Answer: A gorjeta Ã© de R$37,50
```

---

### ğŸ Script 07: RAG AvanÃ§ado com LlamaIndex (BÃ”NUS)
**Arquivo:** `07_llamaindex_rag_advanced.py` | **CapÃ­tulos:** 13, 14

**O que o script faz:**
- Sistema RAG completo com parsing de documentos
- IndexaÃ§Ã£o e embeddings (simulados ou reais com OpenAI)
- Chat com memÃ³ria conversacional
- AvaliaÃ§Ã£o de qualidade (PrecisÃ£o, Recall, F1)

**O que vocÃª aprende:**
- Arquitetura RAG de produÃ§Ã£o: ingestÃ£o â†’ indexaÃ§Ã£o â†’ recuperaÃ§Ã£o â†’ geraÃ§Ã£o
- Como manter o contexto atravÃ©s de mÃºltiplos turnos de conversa
- Como avaliar a qualidade de um sistema RAG

**SaÃ­da esperada:**
```
[Modo Chat]
UsuÃ¡rio: O que Ã© um Transformer?
Assistente: [Contexto: 3 docs] Um Transformer Ã©...
UsuÃ¡rio: E a atenÃ§Ã£o multi-cabeÃ§as?
Assistente: [MemÃ³ria: pergunta anterior + 2 docs] ...
```

---

### ğŸ Script 08: Fine-tuning LoRA/QLoRA (BÃ”NUS)
**Arquivo:** `08_lora_finetuning_example.py` | **CapÃ­tulos:** 9, 10

**O que o script faz:**
- Compara Full Fine-tuning vs LoRA vs QLoRA (cÃ¡lculos numÃ©ricos)
- Mostra as economias de VRAM e parÃ¢metros treinÃ¡veis
- Caso de uso: adaptar LLaMA-7B para um domÃ­nio empresarial (ferroviÃ¡rio)

**O que vocÃª aprende:**
- LoRA: adiciona ~0.1% de parÃ¢metros vs fine-tuning completo
- QLoRA: quantizaÃ§Ã£o de 4 bits + LoRA = GPU de 24GB em vez de 140GB
- Por que o fine-tuning eficiente democratiza os LLMs

**SaÃ­da esperada:**
```
LLaMA-7B:
  Full Fine-tuning: 28 GB VRAM, 7B params
  LoRA (rank=8):    8 GB VRAM, 4.2M params (0.06%)
  QLoRA:            6 GB VRAM, 4.2M params + base 4-bit
```

---

### ï¿½ Script 10: Activation Steering & 3SO (BÃ”NUS)
**Arquivo:** `10_activation_steering_demo.py` | **CapÃ­tulo:** 10

**O que o script faz:**
- Demonstra o steering por ativaÃ§Ãµes: injeÃ§Ã£o de vetores de conceito
- Implementa extraÃ§Ã£o de vetores por ativaÃ§Ã£o contrastiva
- Simula um Sparse Autoencoder (SAE) para decomposiÃ§Ã£o em conceitos
- Implementa uma mÃ¡quina de estados finitos para 3SO (saÃ­das JSON garantidas)
- Compara RLHF/DPO vs Steering com tabela detalhada

**O que vocÃª aprende:**
- O steering modifica as ativaÃ§Ãµes em inferÃªncia: $X_{steered} = X + (c \times V)$
- Como extrair vetores de conceito (mÃ©todo contrastivo, SAE)
- Impacto do coeficiente de steering (muito baixo â†’ nulo, Ã³timo â†’ efetivo, muito alto â†’ descarrilamento)
- O 3SO garante matematicamente uma sintaxe JSON vÃ¡lida
- Quando usar alinhamento vs steering

**SaÃ­da esperada:**
```
STEP 3: Analyzing Coefficient Effect
   Coeff   Direction Î”     Perturbation    Stability
   1.0     12.5Â°           8.2%            âœ… stable
   5.0     45.3Â°           35.1%           âš ï¸ moderate
   15.0    78.2Â°           89.4%           âŒ unstable
```

---

### ï¿½ğŸ† Script 09: Mini-Assistente Completo (PROJETO FINAL)
**Arquivo:** `09_mini_assistant_complet.py` | **CapÃ­tulos:** 11-15

**O que o script faz:**
- Integra TODOS os conceitos: RAG + Agentes + Temperatura + AvaliaÃ§Ã£o
- Sistema completo com base de conhecimento, recuperaÃ§Ã£o, raciocÃ­nio
- Modo interativo para testar diferentes perguntas

**O que vocÃª aprende:**
- Como montar um assistente IA completo de A a Z
- Arquitetura em camadas: Dados â†’ RecuperaÃ§Ã£o â†’ RaciocÃ­nio â†’ GeraÃ§Ã£o
- AvaliaÃ§Ã£o de ponta a ponta de um sistema

**DocumentaÃ§Ã£o dedicada:**
- [INDEX_SCRIPT_09.md](INDEX_SCRIPT_09.md): Arquitetura completa
- [QUICKSTART_SCRIPT_09.md](QUICKSTART_SCRIPT_09.md): InÃ­cio rÃ¡pido em 5 min
- [SCRIPT_09_MAPPING.md](SCRIPT_09_MAPPING.md): Mapeamento cÃ³digo â†” conceitos

---

## ğŸš€ InÃ­cio RÃ¡pido

### 1. Criar um Ambiente Virtual (recomendado)

```bash
# No Windows
python -m venv venv
venv\Scripts\activate

# No macOS / Linux
python -m venv venv
source venv/bin/activate
```

### 2. Instalar DependÃªncias

```bash
# InstalaÃ§Ã£o bÃ¡sica (para scripts 1-5)
pip install torch transformers numpy scikit-learn

# InstalaÃ§Ã£o completa (com visualizaÃ§Ãµes)
pip install torch transformers numpy scikit-learn matplotlib

# Para scripts bÃ´nus (opcional, funcionam em modo demo sem estas)
pip install llama-index openai python-dotenv peft bitsandbytes
```

**Nota:** Os scripts bÃ´nus (06, 07, 08) funcionam **sem dependÃªncias externas** em modo demo.

### 3. Executar um Script

```bash
python 01_tokenization_embeddings.py
python 02_multihead_attention.py
python 03_temperature_softmax.py
python 04_rag_minimal.py
python 05_pass_at_k_evaluation.py
python 06_react_agent_bonus.py
python 07_llamaindex_rag_advanced.py
python 08_lora_finetuning_example.py
python 09_mini_assistant_complet.py    # â† Projeto integrador final
```

---

## ğŸ† Projeto Integrador: Mini-Assistente Completo

**O script principal**: integra TODOS os conceitos dos capÃ­tulos 11-15.

- **Script:** `09_mini_assistant_complet.py`
- **DocumentaÃ§Ã£o:** [INDEX_SCRIPT_09.md](INDEX_SCRIPT_09.md)
- **InÃ­cio RÃ¡pido:** [QUICKSTART_SCRIPT_09.md](QUICKSTART_SCRIPT_09.md)
- **Arquitetura:** [SCRIPT_09_MAPPING.md](SCRIPT_09_MAPPING.md)

---

## ğŸ“– DocumentaÃ§Ã£o Completa

- **[Jornada PedagÃ³gica](PEDAGOGICAL_JOURNEY.md)**: CorrespondÃªncia capÃ­tulo por capÃ­tulo livro â†” scripts
- **[Agentes ReAct](REACT_AGENT_INTEGRATION.md)**: PadrÃ£o ReAct e integraÃ§Ã£o
- **[LlamaIndex RAG](LLAMAINDEX_GUIDE.md)**: Framework RAG avanÃ§ado

---

## ğŸ“ Notas

- **GPU nÃ£o Ã© necessÃ¡rio**: todos os scripts funcionam em CPU (mais lento)
- **CÃ³digo educativo**: prioriza clareza sobre otimizaÃ§Ã£o
- **CompatÃ­vel com Python 3.9+**

---

**Bom aprendizado! ğŸš€**
