# ğŸš€ Quick Start Guide - Bonus Scripts

DÃ©monstration rapide des deux nouveaux bonus scripts. **Aucune installation requise pour les dÃ©mos.**

---

## 1ï¸âƒ£ ReAct Agent - Agent Autonome

**Fichier:** `examples/06_react_agent_bonus.py` (380 lignes)  
**Concept:** Agents autonomes avec pattern ReAct (Thought â†’ Action â†’ Observation)  
**Chapitres:** 13, 14

### ExÃ©cution (30 secondes)

```bash
cd examples
python 06_react_agent_bonus.py
```

### Sortie attendue

```
================================================================================
ğŸ¤– ReAct Agent Demo
================================================================================

ğŸ“‹ Agents RegistrÃ©s:
  âœ“ Calculator Agent
  âœ“ Tool-Based Agent

ğŸ’¬ Task 1: Calcule 15 + 27, puis multiplie par 2
[Iteration 1]
  Thought: L'utilisateur me demande de calculer 15 + 27...
  Action: calculator(a=15, b=27, operation=+)
  Observation: 42
  
[Iteration 2]
  Thought: J'ai maintenant 42, je dois le multiplier par 2...
  Action: calculator(a=42, b=2, operation=*)
  Observation: 84

âœ… Final Answer: 84

[2 itÃ©rations | 0.045 secondes]
```

### Code ClÃ©

```python
# CrÃ©er un agent
agent = Agent(name="MyAgent", max_iterations=10)

# Enregistrer un outil
agent.register_tool(
    name="calculator",
    description="Effectue des calculs simples",
    parameters={"a": float, "b": float, "operation": str},
    func=calculator_function
)

# ExÃ©cuter une tÃ¢che
response = agent.run("Calcule 15 + 27")
```

### IntÃ©gration avec un vrai LLM

**Voir:** `examples/REACT_AGENT_INTEGRATION.md`

```python
from openai import OpenAI

class OpenAIAgent(Agent):
    def __init__(self, model="gpt-4", **kwargs):
        super().__init__(**kwargs)
        self.client = OpenAI()
        self.model = model
    
    def _simulate_llm_reasoning(self, task, context):
        # Appeler OpenAI au lieu de simuler
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content

# Utiliser
agent = OpenAIAgent(model="gpt-4")
```

---

## 2ï¸âƒ£ LlamaIndex RAG - Retrieval-Augmented Generation

**Fichier:** `examples/07_llamaindex_rag_advanced.py` (380+ lignes)  
**Concept:** SystÃ¨me RAG complet avec document indexing, chat persistant, Ã©valuation  
**Chapitres:** 13

### ExÃ©cution (30 secondes)

```bash
cd examples
python 07_llamaindex_rag_advanced.py
```

### Sortie attendue

```
================================================================================
ğŸ¦™ LlamaIndex RAG Advanced Demo
================================================================================

ğŸ“š Phase 1: Chargement des documents
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ“ Transformers : Architecture (675 chars)
  âœ“ Attention Multi-TÃªte (571 chars)
  âœ“ Fine-tuning et Adaptation (653 chars)

ğŸ” Phase 2: CrÃ©ation de l'index vectoriel
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ“ Index crÃ©Ã© avec 3 documents
  âœ“ Dimension embedding: 384

ğŸ’¬ Phase 4: RequÃªtes RAG
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Q1: Qu'est-ce qu'un Transformer?
ğŸ“„ Documents retrievÃ©s:
   - Transformers : Architecture (0f44208b)
   - Attention Multi-TÃªte (90ba7a80)
ğŸ¤– RÃ©ponse:
D'aprÃ¨s le contexte fourni, les Transformers sont des architectures basÃ©es
sur l'attention qui traitent tous les tokens en parallÃ¨le...

ğŸ’¬ Phase 5: Chat avec MÃ©moire
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ‘¤ Utilisateur: Parle-moi des Transformers
ğŸ¤– Bot: D'aprÃ¨s le contexte...

ğŸ“Š Phase 6: Ã‰valuation de QualitÃ©
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Ã‰valuation du Retrieval:
  - Precision@2: 66.67%
  - Recall@2:    75.00%
  - F1:          70.59%

ğŸ’¾ RÃ©sultats exportÃ©s dans: rag_results.json
```

### Code ClÃ©

```python
# 1. CrÃ©er des documents
docs = [
    SimpleDocument(content, metadata={"title": "Transformers"}),
    SimpleDocument(content, metadata={"title": "Attention"})
]

# 2. Indexer
index = VectorIndex(dimension=384)
for doc in docs:
    index.add_document(doc)

# 3. RequÃªte RAG
rag = SimpleRAGEngine(index)
result = rag.query("Qu'est-ce qu'un Transformer?", top_k=2)

# 4. Chat avec mÃ©moire
chatbot = RAGChatbot(rag)
response1 = chatbot.chat("Parle des Transformers")
response2 = chatbot.chat("Et les RNNs?")  # Avec contexte!

# 5. Ã‰valuation
evaluator = RAGEvaluator()
metrics = evaluator.evaluate_retrieval(query, docs, expected)
```

### IntÃ©gration avec LlamaIndex rÃ©el

**Voir:** `examples/LLAMAINDEX_GUIDE.md`

```bash
# Installation
pip install llama-index openai

# Utilisation
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader
from llama_index.core import Settings
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding

# Configuration
Settings.llm = OpenAI(model="gpt-4")
Settings.embed_model = OpenAIEmbedding(model="text-embedding-3-small")

# Charger documents rÃ©els
documents = SimpleDirectoryReader("./documents").load_data()

# CrÃ©er index
index = VectorStoreIndex.from_documents(documents)

# Query engine
query_engine = index.as_query_engine(similarity_top_k=3)
response = query_engine.query("Votre question ici")
```

---

## ğŸ“š Comparaison des Deux Bonus

| Aspect | ReAct Agent | LlamaIndex RAG |
|--------|-------------|----------------|
| **Cas d'usage** | Autonomisation, reasoning | Augmentation avec contexte |
| **Pattern** | Thought â†’ Action â†’ Observation | Retrieval â†’ Augmentation â†’ Generation |
| **Outils** | Fonction, calculatrice, API | Documents, base de connaissances |
| **MÃ©moire** | Historique d'itÃ©rations | Contexte conversationnel |
| **Ã‰valuation** | ItÃ©rations, actions | Precision/Recall, similaritÃ© |
| **ComplexitÃ©** | Moyenne | Moyenne â†’ AvancÃ©e |

---

## ğŸ¯ Quand utiliser quoi?

### Utiliser ReAct Agent si:
- âœ… Vous avez besoin d'**agents autonomes**
- âœ… Le modÃ¨le doit **faire plusieurs actions** (calcul, API call)
- âœ… Vous voulez du **raisonnement pas-Ã -pas**
- âœ… Exemple: Assistant qui peut calculer, chercher une date, etc.

### Utiliser LlamaIndex RAG si:
- âœ… Vous avez des **documents Ã  rechercher** (PDFs, articles)
- âœ… Vous besoin de **rÃ©duire les hallucinations**
- âœ… Vous voulez une **conversation multi-tour** sur des docs
- âœ… Exemple: Chatbot sur votre documentation

### Combiner les deux si:
- âœ… Vous besoin d'un **agent** qui cherche aussi dans des **documents**
- âœ… Pattern: Agent (ReAct) + Outil (RAG query_engine)
- âœ… Exemple: Agent intelligent qui peut raisonner ET chercher

---

## ğŸ”— Ressources ComplÃ¨tes

| Ressource | Fichier | Contenu |
|-----------|---------|---------|
| **ReAct IntÃ©grations** | `REACT_AGENT_INTEGRATION.md` | OpenAI, Claude, Groq, Ollama |
| **LlamaIndex Complet** | `LLAMAINDEX_GUIDE.md` | Installation, concepts, cas d'usage |
| **Liste Scripts** | `examples/README.md` | Tous les 7 scripts avec descriptions |
| **Changelog** | `BONUS_SCRIPTS_CHANGELOG.md` | DÃ©tails des ajouts |

---

## âš¡ Commandes Rapides

```bash
# VÃ©rifier l'installation Python
python --version

# ExÃ©cuter Bonus 1
python examples/06_react_agent_bonus.py

# ExÃ©cuter Bonus 2
python examples/07_llamaindex_rag_advanced.py

# Installer LlamaIndex pour version rÃ©elle
pip install llama-index openai

# VÃ©rifier les rÃ©sultats exportÃ©s
cat examples/rag_results.json | head -20
```

---

## ğŸ“ Notes

- âœ… **Aucune dÃ©pendance pour les dÃ©mos**
- âœ… **Tous les scripts sont testÃ©s**
- âœ… **Bien documentÃ©s avec commentaires**
- âœ… **PrÃªts pour GitHub**

---

**Bon code!** ğŸš€
