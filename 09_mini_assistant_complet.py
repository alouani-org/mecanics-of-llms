#!/usr/bin/env python
"""
Script BONUS 4 : Mini-Assistant Complet - Projet Int√©grateur (Chapitres 11-15)

Ce projet final combine RAG, Agents, Prompting et √âvaluation en un syst√®me coh√©rent.
Il d√©montre comment assembler tous les concepts du livre dans une application r√©elle.

Architecture :
    1. RAG : Indexation et recherche de documents (Ch. 13)
    2. Agent ReAct : Boucle Thought‚ÜíAction‚ÜíObservation (Ch. 14)
    3. Prompting : Zero-shot, Few-shot, Chain-of-Thought (Ch. 11)
    4. √âvaluation : Self-consistency, confidence scoring (Ch. 12, 15)
    5. Outils : Calculatrice, recherche, r√©sum√© (Ch. 14)

Modes d'ex√©cution :
    - Mode STANDALONE : Fonctionne sans API externe (LLM simul√©)
    - Mode PRODUCTION : Int√©gration OpenAI/Claude (d√©commenter le code)

D√©pendances minimales (mode standalone) :
    pip install numpy scikit-learn

D√©pendances production (optionnel) :
    pip install openai anthropic

Utilisation :
    python 09_mini_assistant_complet.py

Points d'extension pour √©tudiants :
    - Ajouter de nouveaux outils (m√©t√©o, actualit√©s, etc.)
    - Int√©grer un vrai LLM (OpenAI, Ollama, etc.)
    - Persister les conversations (SQLite, JSON)
    - Ajouter une interface web (Streamlit, Gradio)
    - Impl√©menter des m√©triques d'√©valuation plus avanc√©es
"""

import re
import json
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
import hashlib

# Imports pour le RAG (vectorisation basique)
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


# ============================================================================
# PARTIE 1 : SYST√àME RAG (Chapitre 13)
# ============================================================================

@dataclass
class Document:
    """Repr√©sentation d'un document dans la base de connaissances."""
    id: str
    content: str
    metadata: Dict[str, Any]
    
    def __repr__(self):
        return f"Doc({self.metadata.get('title', 'Untitled')})"


class RAGSystem:
    """
    Syst√®me RAG complet avec vectorisation TF-IDF et recherche par similarit√©.
    
    En production, remplacer par des embeddings denses (OpenAI, E5, etc.)
    et une base vectorielle (Pinecone, Weaviate, ChromaDB).
    """
    
    def __init__(self):
        self.documents: List[Document] = []
        self.vectorizer: Optional[TfidfVectorizer] = None
        self.doc_vectors: Optional[np.ndarray] = None
    
    def add_document(self, content: str, metadata: Dict[str, Any]) -> str:
        """Ajouter un document √† la base de connaissances."""
        doc_id = hashlib.md5(
            f"{content[:100]}{datetime.now()}".encode()
        ).hexdigest()[:8]
        
        doc = Document(id=doc_id, content=content, metadata=metadata)
        self.documents.append(doc)
        return doc_id
    
    def index_documents(self):
        """Indexer tous les documents (cr√©ation de l'index vectoriel)."""
        if not self.documents:
            raise ValueError("Aucun document √† indexer")
        
        # Vectorisation TF-IDF
        texts = [doc.content for doc in self.documents]
        self.vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words='english',  # Utilisez 'french' pour du fran√ßais
            ngram_range=(1, 2)
        )
        self.doc_vectors = self.vectorizer.fit_transform(texts)
        
        print(f"‚úì Index cr√©√© : {len(self.documents)} documents index√©s")
    
    def retrieve(self, query: str, top_k: int = 3) -> List[Tuple[Document, float]]:
        """
        Rechercher les documents les plus pertinents.
        
        Returns:
            Liste de tuples (Document, score de similarit√©)
        """
        if self.vectorizer is None or self.doc_vectors is None:
            raise ValueError("Index non cr√©√©. Appelez index_documents() d'abord.")
        
        # Vectorisation de la requ√™te
        query_vec = self.vectorizer.transform([query])
        
        # Calcul de similarit√© cosinus
        similarities = cosine_similarity(query_vec, self.doc_vectors).flatten()
        
        # Top-K documents
        top_indices = similarities.argsort()[-top_k:][::-1]
        
        results = [
            (self.documents[idx], similarities[idx])
            for idx in top_indices
        ]
        
        return results


# ============================================================================
# PARTIE 2 : OUTILS (Chapitre 14)
# ============================================================================

class ToolRegistry:
    """Registre d'outils disponibles pour l'agent."""
    
    def __init__(self):
        self.tools: Dict[str, Dict[str, Any]] = {}
    
    def register(self, name: str, description: str, func):
        """Enregistrer un nouvel outil."""
        self.tools[name] = {
            "name": name,
            "description": description,
            "func": func
        }
    
    def get_tools_description(self) -> str:
        """G√©n√©rer une description texte de tous les outils."""
        if not self.tools:
            return "Aucun outil disponible."
        
        desc = "Outils disponibles :\n"
        for tool in self.tools.values():
            desc += f"  - {tool['name']}: {tool['description']}\n"
        return desc
    
    def execute(self, tool_name: str, **kwargs) -> str:
        """Ex√©cuter un outil avec les arguments fournis."""
        if tool_name not in self.tools:
            return f"‚ùå Outil '{tool_name}' inconnu"
        
        try:
            result = self.tools[tool_name]["func"](**kwargs)
            return str(result)
        except Exception as e:
            return f"‚ùå Erreur lors de l'ex√©cution de '{tool_name}': {e}"


# Outils pr√©d√©finis

def tool_calculator(expression: str) -> str:
    """√âvalue une expression math√©matique simple."""
    try:
        # S√©curit√© : whitelist des op√©rations autoris√©es
        allowed = set("0123456789+-*/(). ")
        if not all(c in allowed for c in expression):
            return "Expression invalide (caract√®res interdits)"
        
        result = eval(expression)
        return f"{expression} = {result}"
    except Exception as e:
        return f"Erreur de calcul : {e}"


def tool_search_knowledge(query: str, rag_system: RAGSystem) -> str:
    """Recherche dans la base de connaissances RAG."""
    try:
        results = rag_system.retrieve(query, top_k=2)
        
        if not results:
            return "Aucun document pertinent trouv√©."
        
        response = "Documents trouv√©s :\n"
        for doc, score in results:
            title = doc.metadata.get('title', 'Sans titre')
            snippet = doc.content[:200] + "..."
            response += f"\n[{title}] (score: {score:.2f})\n{snippet}\n"
        
        return response
    except Exception as e:
        return f"Erreur de recherche : {e}"


def tool_current_time() -> str:
    """Retourne l'heure actuelle."""
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def tool_summarize(text: str) -> str:
    """R√©sume un texte (version simplifi√©e)."""
    sentences = text.split('.')
    # Prendre les 2 premi√®res phrases
    summary = '. '.join(sentences[:2]) + '.'
    return f"R√©sum√© : {summary}"


# ============================================================================
# PARTIE 3 : AGENT REACT (Chapitre 14)
# ============================================================================

class ReActAgent:
    """
    Agent autonome avec pattern ReAct (Reason + Act).
    
    Boucle : Thought ‚Üí Action ‚Üí Observation ‚Üí ... ‚Üí Final Answer
    """
    
    def __init__(self, rag_system: RAGSystem, use_real_llm: bool = False):
        self.rag_system = rag_system
        self.tools = ToolRegistry()
        self.history: List[Dict[str, str]] = []
        self.use_real_llm = use_real_llm
        
        # Enregistrement des outils
        self._register_tools()
    
    def _register_tools(self):
        """Enregistrer tous les outils disponibles."""
        self.tools.register(
            "calculator",
            "√âvalue une expression math√©matique (ex: 2+2, 5*3)",
            tool_calculator
        )
        
        self.tools.register(
            "search",
            "Recherche dans la base de connaissances",
            lambda query: tool_search_knowledge(query, self.rag_system)
        )
        
        self.tools.register(
            "current_time",
            "Retourne la date et l'heure actuelles",
            tool_current_time
        )
        
        self.tools.register(
            "summarize",
            "R√©sume un texte long",
            tool_summarize
        )
    
    def _simulate_llm_reasoning(self, prompt: str, step_count: int = 1) -> str:
        """
        Simuler un LLM (mode standalone).
        
        En production, remplacer par un appel √† OpenAI, Claude, etc.
        Apr√®s 1-2 it√©rations, retourner une r√©ponse finale pour √©viter les boucles infinies.
        """
        # D√©tection de patterns simples pour la d√©mo
        prompt_lower = prompt.lower()
        
        # Pattern : question math√©matique
        if any(op in prompt_lower for op in ['calcul', 'combien', '+', '*', '/', '-']):
            # Extraire l'expression math√©matique
            match = re.search(r'(\d+\s*[+\-*/]\s*\d+)', prompt)
            if match:
                expr = match.group(1)
                # Premi√®re it√©ration : appeler la calculatrice
                if step_count <= 1:
                    return f"Thought: Je dois calculer {expr}\nAction: calculator(expression='{expr}')"
                else:
                    # It√©ration suivante : donner la r√©ponse finale
                    try:
                        result = eval(expr)
                        return f"Thought: J'ai obtenu le r√©sultat du calcul.\nFinal Answer: Le r√©sultat de {expr} est {result}."
                    except:
                        return "Thought: J'ai la r√©ponse.\nFinal Answer: Le calcul a √©t√© effectu√© avec succ√®s."
        
        # Pattern : recherche d'information
        if any(word in prompt_lower for word in ['qu\'est-ce', 'd√©finition', 'explique', 'parle-moi', 'qu est ce']):
            # Extraire le sujet
            for keyword in ['transformer', 'attention', 'llm', 'rag', 'agent', 'lora']:
                if keyword in prompt_lower:
                    if step_count <= 1:
                        return f"Thought: Je dois chercher des informations sur {keyword}\nAction: search(query='{keyword}')"
                    else:
                        return f"Thought: J'ai trouv√© des informations pertinentes sur {keyword}.\nFinal Answer: Les documents pertinents expliquent les concepts cl√©s sur le sujet. Selon la base de connaissances, {keyword.upper()} est un concept important couvert en d√©tail."
        
        # Pattern : heure/date
        if any(word in prompt_lower for word in ['heure', 'date', 'aujourd\'hui', 'maintenant', 'quelle heure']):
            if step_count <= 1:
                return "Thought: Je dois obtenir l'heure actuelle\nAction: current_time()"
            else:
                return "Thought: J'ai l'heure actuelle.\nFinal Answer: L'heure a √©t√© obtenue avec succ√®s."
        
        # Par d√©faut : recherche g√©n√©rique
        if step_count <= 1:
            return f"Thought: Je vais chercher des informations sur cette question\nAction: search(query='{prompt[:50]}')"
        else:
            return "Thought: J'ai explor√© la base de connaissances.\nFinal Answer: Bas√© sur les documents trouv√©s, voici ce que j'ai pu d√©terminer sur votre question."
    
    def _call_real_llm(self, prompt: str) -> str:
        """
        Appeler un vrai LLM (OpenAI, Claude, etc.).
        
        √Ä d√©commenter et configurer en production.
        """
        # Exemple avec OpenAI :
        # from openai import OpenAI
        # client = OpenAI()
        # response = client.chat.completions.create(
        #     model="gpt-4",
        #     messages=[{"role": "user", "content": prompt}],
        #     temperature=0.7
        # )
        # return response.choices[0].message.content
        
        raise NotImplementedError("Configuration LLM requise")
    
    def _parse_action(self, response: str) -> Optional[Tuple[str, Dict[str, str]]]:
        """
        Parser la r√©ponse du LLM pour extraire l'action.
        
        Format attendu : Action: tool_name(param1='val1', param2='val2')
        """
        action_match = re.search(r"Action:\s*(\w+)\((.*?)\)", response)
        
        if not action_match:
            return None
        
        tool_name = action_match.group(1)
        params_str = action_match.group(2)
        
        # Parser les param√®tres
        params = {}
        if params_str.strip():
            for param in params_str.split(','):
                if '=' in param:
                    key, val = param.split('=', 1)
                    key = key.strip()
                    val = val.strip().strip("'\"")
                    params[key] = val
        
        return tool_name, params
    
    def run(self, question: str, max_iterations: int = 5, verbose: bool = True) -> Dict[str, Any]:
        """
        Ex√©cuter l'agent sur une question.
        
        Returns:
            Dict avec 'answer', 'steps', 'confidence'
        """
        if verbose:
            print(f"\n{'='*70}")
            print(f"ü§ñ Question : {question}")
            print(f"{'='*70}")
        
        context = f"Question utilisateur : {question}\n\n{self.tools.get_tools_description()}\n"
        steps = []
        
        for iteration in range(1, max_iterations + 1):
            if verbose:
                print(f"\n{'‚îÄ'*70}")
                print(f"‚è≥ It√©ration {iteration}/{max_iterations}")
                print(f"{'‚îÄ'*70}")
            
            # 1. Pens√©e (Thought) - Appel au LLM
            prompt = context + "\n".join([
                f"√âtape {s['iteration']}: {s['thought']}\nAction: {s['action']}\nObservation: {s['observation']}"
                for s in steps
            ])
            
            if self.use_real_llm:
                llm_response = self._call_real_llm(prompt)
            else:
                llm_response = self._simulate_llm_reasoning(question, step_count=iteration)
            
            # Extraire la pens√©e
            thought_match = re.search(r"Thought:\s*(.+?)(?:\n|$)", llm_response)
            thought = thought_match.group(1) if thought_match else "Analyse en cours..."
            
            if verbose:
                print(f"üí≠ Pens√©e : {thought}")
            
            # 2. V√©rifier si r√©ponse finale
            if "final answer:" in llm_response.lower():
                answer = llm_response.split("Final Answer:", 1)[1].strip() if "Final Answer:" in llm_response else llm_response.split("final answer:", 1)[1].strip()
                if verbose:
                    print(f"\n‚úÖ R√©ponse finale : {answer}")
                
                return {
                    "answer": answer,
                    "steps": steps,
                    "iterations": iteration,
                    "confidence": self._calculate_confidence(steps)
                }
            
            # 3. Parser et ex√©cuter l'action
            action_parsed = self._parse_action(llm_response)
            
            if not action_parsed:
                if verbose:
                    print("‚ö†Ô∏è Pas d'action d√©tect√©e")
                continue
            
            tool_name, params = action_parsed
            action_str = f"{tool_name}({', '.join(f'{k}={v}' for k, v in params.items())})"
            
            if verbose:
                print(f"üîß Action : {action_str}")
            
            # 4. Observation - Ex√©cution de l'outil
            observation = self.tools.execute(tool_name, **params)
            
            if verbose:
                print(f"üìä Observation : {observation[:200]}...")
            
            # Sauvegarder l'√©tape
            steps.append({
                "iteration": iteration,
                "thought": thought,
                "action": action_str,
                "observation": observation
            })
            
            # Mettre √† jour le contexte
            context += f"\n√âtape {iteration}:\nPens√©e: {thought}\nAction: {action_str}\nObservation: {observation}\n"
        
        # Max iterations atteint
        final_answer = "Impossible de r√©pondre dans le nombre d'it√©rations autoris√©."
        
        return {
            "answer": final_answer,
            "steps": steps,
            "iterations": max_iterations,
            "confidence": 0.0
        }
    
    def _calculate_confidence(self, steps: List[Dict]) -> float:
        """
        Calculer un score de confiance bas√© sur les √©tapes.
        
        Heuristique simple : plus d'√©tapes r√©ussies = plus de confiance.
        En production, utiliser des m√©triques plus sophistiqu√©es.
        """
        if not steps:
            return 0.0
        
        success_count = sum(
            1 for step in steps 
            if "‚ùå" not in step["observation"]
        )
        
        return min(1.0, success_count / len(steps))


# ============================================================================
# PARTIE 4 : √âVALUATION (Chapitres 12, 15)
# ============================================================================

class AssistantEvaluator:
    """√âvaluation de la qualit√© des r√©ponses de l'assistant."""
    
    @staticmethod
    def evaluate_response(
        question: str,
        response: Dict[str, Any],
        expected_answer: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        √âvaluer une r√©ponse de l'assistant.
        
        M√©triques :
            - Iterations utilis√©es
            - Confidence score
            - Latence (simul√©e)
            - Coh√©rence (si r√©ponse attendue fournie)
        """
        evaluation = {
            "question": question,
            "iterations": response["iterations"],
            "confidence": response["confidence"],
            "steps_count": len(response["steps"]),
            "success": response["confidence"] > 0.5
        }
        
        # √âvaluation de coh√©rence (si r√©ponse attendue)
        if expected_answer:
            # Similarit√© simple bas√©e sur mots communs
            answer_words = set(response["answer"].lower().split())
            expected_words = set(expected_answer.lower().split())
            
            if answer_words and expected_words:
                overlap = len(answer_words & expected_words)
                total = len(answer_words | expected_words)
                evaluation["coherence_score"] = overlap / total
            else:
                evaluation["coherence_score"] = 0.0
        
        return evaluation
    
    @staticmethod
    def self_consistency_check(
        agent: ReActAgent,
        question: str,
        num_samples: int = 3
    ) -> Dict[str, Any]:
        """
        V√©rifier la coh√©rence des r√©ponses (self-consistency).
        
        G√©n√®re plusieurs r√©ponses et mesure leur accord.
        Concept du chapitre 12.
        """
        print(f"\n{'='*70}")
        print(f"üî¨ Test de self-consistency ({num_samples} √©chantillons)")
        print(f"{'='*70}")
        
        answers = []
        
        for i in range(num_samples):
            print(f"\n√âchantillon {i+1}/{num_samples}...")
            response = agent.run(question, verbose=False)
            answers.append(response["answer"])
        
        # Calculer la fr√©quence de chaque r√©ponse
        from collections import Counter
        answer_counts = Counter(answers)
        most_common = answer_counts.most_common(1)[0]
        
        consistency_score = most_common[1] / num_samples
        
        return {
            "question": question,
            "num_samples": num_samples,
            "unique_answers": len(answer_counts),
            "most_common_answer": most_common[0],
            "consistency_score": consistency_score,
            "all_answers": answers
        }


# ============================================================================
# PARTIE 5 : D√âMONSTRATION & MAIN
# ============================================================================

def initialize_knowledge_base() -> RAGSystem:
    """Initialiser une base de connaissances avec des documents de d√©mo."""
    rag = RAGSystem()
    
    # Documents sur les LLMs et l'IA
    documents = [
        {
            "content": """
Les Transformers sont une architecture de r√©seaux de neurones introduite en 2017.
Ils utilisent un m√©canisme d'attention qui permet de traiter tous les tokens en parall√®le,
contrairement aux RNN qui traitent s√©quentiellement. Les Transformers sont la base
de tous les LLMs modernes comme GPT, BERT, LLaMA, Claude et Mistral.
L'architecture comprend un encodeur et un d√©codeur, bien que les LLMs modernes
utilisent souvent seulement la partie d√©codeur.
            """,
            "metadata": {"title": "Architecture Transformer", "chapter": 3}
        },
        {
            "content": """
Le RAG (Retrieval-Augmented Generation) est une technique qui combine la recherche
d'information avec la g√©n√©ration de texte. Avant de r√©pondre √† une question, le syst√®me
recherche d'abord des documents pertinents dans une base de connaissances, puis utilise
ces documents comme contexte pour g√©n√©rer une r√©ponse plus pr√©cise et factuelle.
Le RAG permet de r√©duire les hallucinations et de mettre √† jour les connaissances
sans r√©entra√Æner le mod√®le.
            """,
            "metadata": {"title": "RAG et syst√®mes augment√©s", "chapter": 13}
        },
        {
            "content": """
Les agents autonomes utilisent le pattern ReAct (Reason + Act) pour r√©soudre des probl√®mes
complexes. L'agent entre dans une boucle it√©rative : il r√©fl√©chit (Thought), d√©cide d'une
action √† effectuer (Action), observe le r√©sultat (Observation), puis recommence jusqu'√†
trouver la r√©ponse. Les agents peuvent utiliser des outils externes comme des calculatrices,
des API ou des bases de donn√©es. Le Model Context Protocol (MCP) standardise la mani√®re
dont ces outils sont int√©gr√©s.
            """,
            "metadata": {"title": "Agents autonomes", "chapter": 14}
        },
        {
            "content": """
L'√©valuation des LLMs utilise plusieurs m√©triques. Pass@k mesure la probabilit√© de succ√®s
en k tentatives. La self-consistency v√©rifie si le mod√®le donne la m√™me r√©ponse plusieurs fois.
La perplexit√© mesure la qualit√© de la pr√©diction du prochain token. Pour les agents,
on √©value le taux de succ√®s, le nombre d'it√©rations et la robustesse aux erreurs.
Les benchmarks comme HumanEval (code) et MMLU (connaissances g√©n√©rales) sont standards.
            """,
            "metadata": {"title": "√âvaluation des LLMs", "chapter": 12}
        },
        {
            "content": """
LoRA (Low-Rank Adaptation) est une technique de fine-tuning efficace qui g√®le le mod√®le
de base et ajoute de petites matrices entra√Ænables. Cela r√©duit drastiquement le nombre
de param√®tres √† entra√Æner (souvent moins de 1% du mod√®le total). QLoRA combine LoRA
avec la quantification 4-bit, permettant de fine-tuner des mod√®les de 65B param√®tres
sur une seule carte GPU grand public. Ces techniques ont d√©mocratis√© l'acc√®s au fine-tuning.
            """,
            "metadata": {"title": "LoRA et QLoRA", "chapter": 9}
        }
    ]
    
    for doc in documents:
        rag.add_document(doc["content"], doc["metadata"])
    
    rag.index_documents()
    
    return rag


def run_demo():
    """D√©monstration compl√®te du mini-assistant."""
    print("\n" + "="*70)
    print("üöÄ MINI-ASSISTANT COMPLET - PROJET INT√âGRATEUR")
    print("="*70)
    print("\nCe projet combine :")
    print("  ‚Ä¢ RAG (Chapitre 13) : Recherche de documents")
    print("  ‚Ä¢ Agents ReAct (Chapitre 14) : Boucle autonome")
    print("  ‚Ä¢ Prompting (Chapitre 11) : G√©n√©ration structur√©e")
    print("  ‚Ä¢ √âvaluation (Chapitres 12, 15) : M√©triques de qualit√©")
    
    # Phase 1 : Initialisation
    print("\n" + "="*70)
    print("üìö Phase 1 : Initialisation de la base de connaissances")
    print("="*70)
    
    rag_system = initialize_knowledge_base()
    
    # Phase 2 : Cr√©ation de l'agent
    print("\n" + "="*70)
    print("ü§ñ Phase 2 : Cr√©ation de l'agent")
    print("="*70)
    
    agent = ReActAgent(rag_system, use_real_llm=False)
    print(f"‚úì Agent cr√©√© avec {len(agent.tools.tools)} outils")
    
    # Phase 3 : Questions de test
    print("\n" + "="*70)
    print("üí¨ Phase 3 : Questions de test")
    print("="*70)
    
    test_questions = [
        "Qu'est-ce qu'un Transformer ?",
        "Combien font 15 * 8 ?",
        "Explique-moi le RAG",
    ]
    
    results = []
    evaluator = AssistantEvaluator()
    
    for i, question in enumerate(test_questions, 1):
        print(f"\n{'#'*70}")
        print(f"Question {i}/{len(test_questions)}")
        print(f"{'#'*70}")
        
        response = agent.run(question, max_iterations=3, verbose=True)
        
        # √âvaluation
        evaluation = evaluator.evaluate_response(question, response)
        results.append({
            "question": question,
            "response": response,
            "evaluation": evaluation
        })
    
    # Phase 4 : Rapport d'√©valuation
    print("\n" + "="*70)
    print("üìä Phase 4 : Rapport d'√©valuation")
    print("="*70)
    
    print("\nR√©sum√© des performances :")
    print("-" * 70)
    
    for i, result in enumerate(results, 1):
        eval_data = result["evaluation"]
        print(f"\nQuestion {i} : {result['question'][:50]}...")
        print(f"  ‚Ä¢ It√©rations : {eval_data['iterations']}")
        print(f"  ‚Ä¢ Confiance : {eval_data['confidence']:.2%}")
        print(f"  ‚Ä¢ Succ√®s : {'‚úÖ' if eval_data['success'] else '‚ùå'}")
    
    # Statistiques globales
    avg_iterations = np.mean([r["evaluation"]["iterations"] for r in results])
    avg_confidence = np.mean([r["evaluation"]["confidence"] for r in results])
    success_rate = np.mean([r["evaluation"]["success"] for r in results])
    
    print("\n" + "="*70)
    print("üìà Statistiques globales")
    print("="*70)
    print(f"  ‚Ä¢ Nombre de questions : {len(results)}")
    print(f"  ‚Ä¢ It√©rations moyennes : {avg_iterations:.1f}")
    print(f"  ‚Ä¢ Confiance moyenne : {avg_confidence:.2%}")
    print(f"  ‚Ä¢ Taux de succ√®s : {success_rate:.2%}")
    
    # Phase 5 : Test de self-consistency (optionnel)
    print("\n" + "="*70)
    print("üî¨ Phase 5 : Test de self-consistency (BONUS)")
    print("="*70)
    print("\nCe test g√©n√®re plusieurs r√©ponses pour la m√™me question")
    print("et mesure leur coh√©rence (concept du chapitre 12).")
    
    consistency_test = evaluator.self_consistency_check(
        agent,
        "Qu'est-ce que le RAG ?",
        num_samples=3
    )
    
    print(f"\nR√©sultats :")
    print(f"  ‚Ä¢ R√©ponse majoritaire : {consistency_test['most_common_answer'][:80]}...")
    print(f"  ‚Ä¢ Score de coh√©rence : {consistency_test['consistency_score']:.2%}")
    print(f"  ‚Ä¢ R√©ponses uniques : {consistency_test['unique_answers']}/{consistency_test['num_samples']}")
    
    # Conclusion
    print("\n" + "="*70)
    print("‚úÖ D√âMONSTRATION TERMIN√âE")
    print("="*70)
    print("\nüí° Points d'extension pour les √©tudiants :")
    print("  1. Int√©grer un vrai LLM (OpenAI, Claude, Ollama)")
    print("  2. Ajouter de nouveaux outils (m√©t√©o, actualit√©s, etc.)")
    print("  3. Persister les conversations dans une base de donn√©es")
    print("  4. Cr√©er une interface web avec Streamlit ou Gradio")
    print("  5. Impl√©menter des m√©triques d'√©valuation plus avanc√©es")
    print("  6. Ajouter du logging et du monitoring en production")
    print("  7. G√©rer les erreurs et timeouts plus robustement")
    print("\nüìñ R√©f√©rence : Voir chapitres 11-15 du livre pour les concepts d√©taill√©s.")
    print()


if __name__ == "__main__":
    run_demo()
