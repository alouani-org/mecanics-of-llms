# Script 09 : Mapping D√©taill√© aux Chapitres du Livre

## üìç Comment Chaque Section du Script Correspond au Livre

Ce document montre **exactement o√π** chaque concept du livre est illustr√© dans le Script 09.

---

## Chapitre 11 : Strat√©gies de G√©n√©ration et Prompting

### 11.1 Prompting : Zero-shot, Few-shot, Chain-of-Thought

**O√π dans le script** :
```python
def _simulate_llm_reasoning(self, prompt: str, step_count: int = 1) -> str:
    """
    Simule un LLM qui fait du prompting structur√©.
    
    Cette fonction impl√©mente les techniques du Chapitre 11 :
    - Chain-of-Thought : "Thought: ... Action: ..."
    - Structuration explicite des √©tapes
    - Prompting z√©ro-shot (pas d'exemples dans la d√©mo)
    """
```

**Code du Livre (Ch. 11)** :
```
Prompt z√©ro-shot :
"Question: Qu'est-ce qu'un Transformer ?"

Prompt avec CoT :
"R√©fl√©chis √©tape par √©tape.
Pens√©e: ...
Action: ...
Observation: ..."
```

**Dans le Script** :
```python
# Ligne 119-125 : D√©tection de patterns (CoT implicite)
if "qu'est-ce" in prompt_lower:
    return f"Thought: Je dois chercher...\nAction: search(...)"

# Ligne 244-260 : Parsing du pattern Thought/Action
thought_match = re.search(r"Thought:\s*(.+?)(?:\n|$)", llm_response)
action_match = re.search(r"Action:\s*(\w+)\((.*?)\)", response)
```

**Lien** : ‚úÖ Le script montre comment structurer un prompting en √©tapes claires (CoT).

---

### 11.2 Temp√©rature et Sampling

**O√π dans le script** :
```python
# Le script SIMULE la temp√©tature (pas d'impl√©mentation r√©elle)
# Mais permet de voir comment diff√©rentes "strat√©gies" (greedy vs sampling)
# pourraient √™tre impl√©ment√©es.
```

**Code du Livre (Ch. 11)** :
```python
temperature = 0.7
logits = logits / temperature
probs = softmax(logits)
next_token = sample(probs)  # vs argmax(probs) pour greedy
```

**Extension du Script** :
Pour int√©grer la temp√©rature r√©elle :
```python
def _simulate_llm_reasoning_with_temp(self, prompt, temperature=0.7):
    # Simuler diff√©rentes r√©ponses selon la T
    if temperature < 0.3:
        return "R√©ponse d√©terministe"
    elif temperature > 1.0:
        return "R√©ponse cr√©ative et vari√©e"
```

**Lien** : ‚ö†Ô∏è Le script simplifie la temp√©rature (concept mentionn√© mais pas impl√©ment√©).

---

## Chapitre 12 : Mod√®les de Raisonnement et √âvaluation

### 12.1 Pass@k et Pass^k

**O√π dans le script** :
```python
class AssistantEvaluator:
    """√âvaluation de la qualit√© des r√©ponses de l'assistant."""
    
    @staticmethod
    def evaluate_response(question, response, expected_answer=None):
        # M√©triques cl√©s
        evaluation = {
            "iterations": response["iterations"],
            "confidence": response["confidence"],
            "success": response["confidence"] > 0.5
        }
```

**Code du Livre (Ch. 12)** :
```
Pass@k = 1 - (1 - p)^k

Exemple :
- p_success = 0.6 (probabilit√© de succ√®s d'une tentative)
- Pass@1 = 0.6 (une seule tentative)
- Pass@5 = 1 - (1-0.6)^5 = 1 - 0.01024 = 98.976%
```

**Dans le Script (Ligne 356-366)** :
```python
success_count = sum(
    1 for step in steps 
    if "‚ùå" not in step["observation"]
)
confidence = min(1.0, success_count / len(steps))
```

**Calcul de confiance simul√©** :
- Chaque √©tape r√©ussie = +confiance
- Implicitement : `confidence ‚âà (succ√®s / iterations)`

**Lien** : ‚úÖ Le script montre comment √©valuer la r√©ussite et la confiance.

---

### 12.2 Self-Consistency

**O√π dans le script** :
```python
@staticmethod
def self_consistency_check(agent, question, num_samples=3) -> Dict:
    """
    V√©rifier la coh√©rence des r√©ponses (self-consistency).
    
    G√©n√®re plusieurs r√©ponses et mesure leur accord.
    Concept du chapitre 12.
    """
    answers = []
    for i in range(num_samples):
        response = agent.run(question, verbose=False)
        answers.append(response["answer"])
    
    # Calculer la fr√©quence de chaque r√©ponse
    from collections import Counter
    answer_counts = Counter(answers)
    most_common = answer_counts.most_common(1)[0]
    
    consistency_score = most_common[1] / num_samples
    
    return {
        "consistency_score": consistency_score,
        "unique_answers": len(answer_counts)
    }
```

**Code du Livre (Ch. 12)** :
```
Self-consistency = "Pose la question k fois, compte les r√©ponses identiques"

Score = r√©ponses identiques / k

Exemple :
- k=3 essais
- R√©ponses : [A, A, A]
- Score = 3/3 = 100% (tr√®s coh√©rent)

Exemple 2 :
- R√©ponses : [A, B, C]
- Score = 1/3 = 33% (tr√®s incoh√©rent)
```

**Dans le Script (Ligne 379-399)** :
```python
for i in range(num_samples):
    response = agent.run(question, verbose=False)
    answers.append(response["answer"])

answer_counts = Counter(answers)
most_common = answer_counts.most_common(1)[0]
consistency_score = most_common[1] / num_samples
```

**Lien** : ‚úÖ Le script impl√©mente exactement self-consistency tel que d√©crit au Ch. 12.

---

## Chapitre 13 : Syst√®mes Augment√©s et RAG

### 13.1 Indexation Vectorielle

**O√π dans le script** :
```python
class RAGSystem:
    """
    Syst√®me RAG complet avec vectorisation TF-IDF et recherche par similarit√©.
    
    En production, remplacer par des embeddings denses (OpenAI, E5, etc.)
    et une base vectorielle (Pinecone, Weaviate, ChromaDB).
    """
    
    def index_documents(self):
        """Indexer tous les documents (cr√©ation de l'index vectoriel)."""
        if not self.documents:
            raise ValueError("Aucun document √† indexer")
        
        # Vectorisation TF-IDF
        texts = [doc.content for doc in self.documents]
        self.vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words='english',
            ngram_range=(1, 2)
        )
        self.doc_vectors = self.vectorizer.fit_transform(texts)
```

**Code du Livre (Ch. 13)** :
```
Pipeline RAG :
1. Indexation : Convertir documents en vecteurs
2. Retrieval : Chercher les K documents pertinents
3. Augmentation : Injecter contexte dans le prompt
4. G√©n√©ration : LLM r√©pond en s'appuyant sur le contexte
```

**Dans le Script (Ligne 73-100)** :
```python
# 1. Indexation
self.vectorizer = TfidfVectorizer(...)
self.doc_vectors = self.vectorizer.fit_transform(texts)

# 2. Retrieval
def retrieve(self, query, top_k=3):
    query_vec = self.vectorizer.transform([query])
    similarities = cosine_similarity(query_vec, self.doc_vectors).flatten()
    top_indices = similarities.argsort()[-top_k:][::-1]
    return [(self.documents[idx], similarities[idx]) for idx in top_indices]
```

**Lien** : ‚úÖ Le script montre un RAG complet (indexation + retrieval).

---

### 13.2 Similarit√© Cosinus

**O√π dans le script** :
```python
from sklearn.metrics.pairwise import cosine_similarity

def retrieve(self, query: str, top_k: int = 3) -> List[Tuple[Document, float]]:
    # Vectorisation de la requ√™te
    query_vec = self.vectorizer.transform([query])
    
    # Calcul de similarit√© cosinus
    similarities = cosine_similarity(query_vec, self.doc_vectors).flatten()
```

**Code du Livre (Ch. 13)** :
```
Similarit√© cosinus entre deux vecteurs u et v :

sim(u, v) = (u ¬∑ v) / (||u|| * ||v||)

R√©sultat : score entre 0 et 1
- 0 : totalement diff√©rent
- 1 : identique
```

**Lien** : ‚úÖ Le script utilise exactement la similarit√© cosinus.

---

## Chapitre 14 : Protocoles Standards Agentiques

### 14.1 Pattern ReAct

**O√π dans le script** :
```python
class ReActAgent:
    """
    Agent autonome avec pattern ReAct (Reason + Act).
    
    Boucle : Thought ‚Üí Action ‚Üí Observation ‚Üí ... ‚Üí Final Answer
    """
    
    def run(self, question: str, max_iterations: int = 5) -> Dict:
        for iteration in range(1, max_iterations + 1):
            # 1. Pens√©e (Thought)
            llm_response = self._simulate_llm_reasoning(question, step_count=iteration)
            thought = re.search(r"Thought:\s*(.+?)(?:\n|$)", llm_response).group(1)
            
            # 2. Action
            action_parsed = self._parse_action(llm_response)
            tool_name, params = action_parsed
            
            # 3. Observation
            observation = self.tools.execute(tool_name, **params)
            
            # 4. Boucle ou R√©ponse
            if "final answer:" in llm_response.lower():
                return {"answer": answer, ...}
```

**Code du Livre (Ch. 14)** :
```
Boucle ReAct :

1. Pens√©e : Que dois-je faire ?
   "Thought: Je dois chercher des informations sur le Transformer"

2. Action : Quel outil utiliser ?
   "Action: search(query='Transformer')"

3. Observation : Quel r√©sultat ?
   "Observation: [Documents pertinents...]"

4. [Continuer ou arr√™ter]
   "Final Answer: Les Transformers sont..."
```

**Dans le Script (Ligne 228-290)** :
```python
# Chaque it√©ration suit le pattern ReAct :
for iteration in range(1, max_iterations + 1):
    print(f"üí≠ Pens√©e : {thought}")           # Thought
    print(f"üîß Action : {action_str}")        # Action
    print(f"üìä Observation : {observation}")  # Observation
    # Boucle continue jusqu'√† "Final Answer"
```

**Lien** : ‚úÖ Le script impl√©mente parfaitement la boucle ReAct.

---

### 14.2 Tool Calling et Registration

**O√π dans le script** :
```python
class ToolRegistry:
    """Registre d'outils disponibles pour l'agent."""
    
    def register(self, name: str, description: str, func):
        """Enregistrer un nouvel outil."""
        self.tools[name] = {
            "name": name,
            "description": description,
            "func": func
        }
    
    def execute(self, tool_name: str, **kwargs) -> str:
        """Ex√©cuter un outil avec les arguments fournis."""
        if tool_name not in self.tools:
            return f"‚ùå Outil '{tool_name}' inconnu"
        
        result = self.tools[tool_name]["func"](**kwargs)
        return str(result)
```

**Code du Livre (Ch. 14)** :
```
Tool Calling (chapitre 14) :

1. D√©finir les outils disponibles
   - Nom : "search"
   - Description : "Recherche dans la base de connaissances"
   - Fonction : fonction_recherche()

2. Agent appelle l'outil
   "Action: search(query='Transformer')"

3. Ex√©cution
   result = tools.execute("search", query="Transformer")

4. Observation retourn√©e au LLM
```

**Dans le Script (Ligne 181-197)** :
```python
# Registration (Chapitre 14)
self.tools.register(
    "calculator",
    "√âvalue une expression math√©matique",
    tool_calculator
)

# Tool Calling
tool_name, params = self._parse_action(llm_response)
observation = self.tools.execute(tool_name, **params)
```

**Lien** : ‚úÖ Le script montre tool registration et tool calling.

---

### 14.3 Model Context Protocol (MCP)

**O√π dans le script** :
```python
# Le script simule le MCP avec le ToolRegistry
# En production, utiliser le vrai MCP :

# from mcp.server import MCPServer
# server = MCPServer("agent")
# @server.call_tool
# def my_tool(param1: str) -> str:
#     return "r√©sultat"
```

**Code du Livre (Ch. 14)** :
```
MCP = Standard pour d√©finir les outils

Sp√©cification :
{
    "name": "search",
    "description": "Recherche documents",
    "inputSchema": {
        "type": "object",
        "properties": {
            "query": {"type": "string"}
        },
        "required": ["query"]
    }
}
```

**Lien** : ‚ö†Ô∏è Le script simule MCP (voir annexe pour int√©gration r√©elle).

---

## Chapitre 15 : Mise en Production

### 15.1 Gestion d'Erreurs et Robustesse

**O√π dans le script** :
```python
class ToolRegistry:
    def execute(self, tool_name: str, **kwargs) -> str:
        """Ex√©cuter un outil avec les arguments fournis."""
        if tool_name not in self.tools:
            return f"‚ùå Outil '{tool_name}' inconnu"  # Error handling
        
        try:
            result = self.tools[tool_name]["func"](**kwargs)
            return str(result)
        except Exception as e:
            return f"‚ùå Erreur lors de l'ex√©cution: {e}"  # Exception handling
```

**Code du Livre (Ch. 15)** :
```
Production checklist :

1. ‚úÖ Gestion d'erreurs (try/except)
2. ‚úÖ Validation des entr√©es
3. ‚úÖ Logging structur√©
4. ‚úÖ Timeouts (max_iterations ici)
5. ‚úÖ Fallbacks et retry
6. ‚úÖ Monitoring et m√©triques
```

**Lien** : ‚úÖ Le script impl√©mente les √©l√©ments cl√©s pour la production.

---

### 15.2 Logging et Observation

**O√π dans le script** :
```python
def run(self, question: str, max_iterations: int = 5, verbose: bool = True):
    if verbose:
        print(f"\n{'='*70}")
        print(f"ü§ñ Question : {question}")
        print(f"{'='*70}")
    
    for iteration in range(1, max_iterations + 1):
        if verbose:
            print(f"\n{'‚îÄ'*70}")
            print(f"‚è≥ It√©ration {iteration}/{max_iterations}")
            print(f"{'‚îÄ'*70}")
            print(f"üí≠ Pens√©e : {thought}")
            print(f"üîß Action : {action_str}")
            print(f"üìä Observation : {observation[:200]}...")
```

**Code du Livre (Ch. 15)** :
```
Logging production :

1. Chaque √©tape trac√©e (Thought, Action, Observation)
2. Timestamps et IDs de session
3. M√©triques : latence, tokens, co√ªt
4. Erreurs et warnings
5. Dashboard de monitoring
```

**Lien** : ‚úÖ Le script montre le logging verbeux (production-ready).

---

### 15.3 √âvaluation et M√©triques

**O√π dans le script** :
```python
class AssistantEvaluator:
    @staticmethod
    def evaluate_response(question, response, expected_answer=None):
        evaluation = {
            "iterations": response["iterations"],
            "confidence": response["confidence"],
            "success": response["confidence"] > 0.5
        }
        return evaluation
    
    @staticmethod
    def self_consistency_check(agent, question, num_samples=3):
        # G√©n√©rer k r√©ponses
        # Mesurer la coh√©rence
        # Retourner les m√©triques
```

**Code du Livre (Ch. 15)** :
```
M√©triques en production :

1. ‚úÖ Success rate (% de questions r√©pondues)
2. ‚úÖ Latency (P50, P95, P99)
3. ‚úÖ Quality (confiance, coh√©rence)
4. ‚úÖ Cost (nombre de tokens, appels API)
5. ‚úÖ User feedback (ratings, corrections)
```

**Lien** : ‚úÖ Le script mesure success, confiance, et coh√©rence.

---

## üéØ R√©sum√© : Couverture Compl√®te

| Chapitre | Concept | Impl√©ment√© ? | O√π dans le script ? |
|----------|---------|-------------|-------------------|
| 11 | Prompting (CoT) | ‚úÖ | `_simulate_llm_reasoning()` |
| 11 | Temp√©rature | ‚ö†Ô∏è Simul√© | Extension possible |
| 12 | Pass@k / Confiance | ‚úÖ | `_calculate_confidence()` |
| 12 | Self-consistency | ‚úÖ | `self_consistency_check()` |
| 13 | RAG Pipeline | ‚úÖ | `RAGSystem` classe compl√®te |
| 13 | Similarit√© Cosinus | ‚úÖ | `retrieve()` avec cosine_similarity |
| 14 | Pattern ReAct | ‚úÖ | Boucle compl√®te `run()` |
| 14 | Tool Calling | ‚úÖ | `ToolRegistry.execute()` |
| 14 | Tool Registration | ‚úÖ | `ToolRegistry.register()` |
| 15 | Gestion d'erreurs | ‚úÖ | try/except dans `execute()` |
| 15 | Logging | ‚úÖ | `verbose=True` avec print() |
| 15 | M√©triques | ‚úÖ | `AssistantEvaluator` |

---

## üöÄ Comment √âtendre Chaque Concept

### Prompting (Ch. 11)
Ajouter Few-shot examples :
```python
few_shot = """
Exemple 1 : Q: "Combien ?" ‚Üí A: "calculer"
Exemple 2 : Q: "Qu'est-ce ?" ‚Üí A: "chercher"
Question : ...
"""
```

### √âvaluation (Ch. 12)
Ajouter m√©triques ROUGE/BERTScore :
```python
from rouge_score import rouge_scorer
scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'])
scores = scorer.score(reference, hypothesis)
```

### RAG (Ch. 13)
Int√©grer embeddings denses :
```python
from openai import OpenAI
client = OpenAI()
embedding = client.embeddings.create(
    model="text-embedding-3-small",
    input=text
).data[0].embedding
```

### Agents (Ch. 14)
Ajouter le vrai MCP :
```python
from mcp.server import Server
server = Server("agent")
@server.call_tool("search", query: str)
async def search_tool(query: str):
    return retrieve(query)
```

---

**Chaque ligne de code dans Script 09 correspond √† un concept du livre. C'est votre pont entre th√©orie et pratique ! üåâ**
