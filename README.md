# Scripts Pratiques : ExpÃ©rimenter les Concepts LLM

ğŸŒ **[English Version](#english-version)** | ğŸ“– **FranÃ§ais**

Collection de **9 scripts Python exÃ©cutables** (+ documentation) pour expÃ©rimenter les concepts clÃ©s prÃ©sentÃ©s dans le livre **"La MÃ©canique des LLM"**.

> ğŸ“š **Ã€ propos** : Ces scripts accompagnent les chapitres du livre. Voir [Correspondance Livre â†” Scripts](docs/fr/PEDAGOGICAL_JOURNEY.md) pour les liens dÃ©taillÃ©s.

**ğŸ“• Acheter le livre :**
- **BrochÃ©** : [Amazon](https://amzn.eu/d/3oREERI)
- **Kindle** : [Amazon](https://amzn.eu/d/b7sG5iw)

---

## ğŸ“‹ Vue d'Ensemble des Scripts

| # | Script | Chapitre(s) | Concepts | Status |
|---|--------|-----------|----------|--------|
| 1 | [01_tokenization_embeddings.py](#script-1--tokenisation-et-embeddings) | 2 | Tokenisation, impact sur la longueur de sÃ©quence | âœ… |
| 2 | [02_multihead_attention.py](#script-2--multi-head-attention) | 3 | Self-attention, multi-head, poids d'attention | âœ… |
| 3 | [03_temperature_softmax.py](#script-3--tempÃ©rature-et-softmax) | 7, 11 | TempÃ©rature, softmax, entropie | âœ… |
| 4 | [04_rag_minimal.py](#script-4--pipeline-rag-minimal) | 13 | Pipeline RAG, retrieval, similaritÃ© cosinus | âœ… |
| 5 | [05_pass_at_k_evaluation.py](#script-5--Ã©valuation-pass-k) | 12 | Pass@k, Pass^k, Ã©valuation de modÃ¨les | âœ… |
| ğŸ 6 | [06_react_agent_bonus.py](#bonus-1--react-agent-avec-framework-gÃ©nÃ©rique) | 14, 15 | **Agents ReAct, tool registration, MCP** | âœ… BONUS |
| ğŸ 7 | [07_llamaindex_rag_advanced.py](#bonus-2--rag-avancÃ©-avec-llamaindex) | 13, 14 | **RAG avancÃ©, indexing, chat persistant** | âœ… BONUS |
| ğŸ 8 | [08_lora_finetuning_example.py](#bonus-3--lora-et-fine-tuning) | 9, 10 | **LoRA, QLoRA, fine-tuning comparatif** | âœ… BONUS |
| ğŸ† **9** | [09_mini_assistant_complet.py](#-projet-intÃ©grateur--mini-assistant-complet) | **11-15** | **ğŸ¯ Projet Final IntÃ©grateur** | âœ… FLAGSHIP |

## ğŸš€ DÃ©marrage Rapide

### 1. CrÃ©er un environnement virtuel (recommandÃ©)

```bash
# Sur Windows
python -m venv venv
venv\Scripts\activate

# Sur macOS / Linux
python -m venv venv
source venv/bin/activate
```

### 2. Installer les dÃ©pendances

```bash
# Installation basique (pour les scripts 1-5)
pip install torch transformers numpy scikit-learn

# Installation complÃ¨te (avec visualisations)
pip install torch transformers numpy scikit-learn matplotlib

# Pour les bonus (optionnel, scripts fonctionnent aussi sans)
pip install llama-index openai python-dotenv peft bitsandbytes
```

**Note:** Les scripts bonus (06, 07, 08) fonctionnent **sans dÃ©pendances externes**
en mode dÃ©mo. Ils utilisent des simulations/calculs pour illustrer les concepts.

### 3. ExÃ©cuter un script

```bash
python 01_tokenization_embeddings.py
python 02_multihead_attention.py
python 03_temperature_softmax.py
python 04_rag_minimal.py
python 05_pass_at_k_evaluation.py
python 06_react_agent_bonus.py
python 07_llamaindex_rag_advanced.py
python 08_lora_finetuning_example.py
python 09_mini_assistant_complet.py    # â† Projet intÃ©grateur final
```

## ğŸ“– DÃ©tails par Script

### Script 1 : Tokenisation et Embeddings (Chapitre 2)

**Voir:** `02-representation-texte-modeles-sequentiels.md`

Illustre :
- Comment les tokenizers (BPE, WordPiece) fragmentent le texte.
- L'impact du nombre de tokens sur le coÃ»t computationnel.
- Les diffÃ©rences entre langues (franÃ§ais vs anglais).

```bash
python 01_tokenization_embeddings.py
```

**Exemple de sortie:**
```
Texte: L'IA est utile
  Nombre de tokens: 6
  Token IDs: [43, 6, 3539, 1556, 3384, 576]
  Tokens (texte): ['L', "'", 'IA', 'Ä est', 'Ä ut', 'ile']

Texte court (7 caractÃ¨res) â†’ 3 tokens
Texte long (700 caractÃ¨res) â†’ 300 tokens
Facteur: 100.0x

âš ï¸ IMPLICATIONS:
  â€¢ Plus de tokens = plus de VRAM
  â€¢ Plus de tokens = latence plus Ã©levÃ©e
  â€¢ CoÃ»t d'infÃ©rence âˆ O(nÂ²) pour l'attention
```

---

### Script 2 : Multi-Head Attention (Chapitre 3)

**Voir:** `03-architecture-transformer.md`

Simule une couche d'attention multi-tÃªte minimale :
- Projections Q, K, V.
- Calcul des scores d'attention.
- Visualisation de comment chaque tÃªte focalise diffÃ©remment.

```bash
python 02_multihead_attention.py
```

**Exemple de sortie:**
```
EntrÃ©e x shape: (1, 4, 64)
  (batch=1, seq_len=4, d_model=64)

TÃªte 0:
  Poids d'attention (aprÃ¨s softmax):
    [[0.25 0.35 0.25 0.15]  # Le "regarde" 35% vers "chat"
     [0.10 0.60 0.20 0.10]  # "chat" regarde 60% vers "dort"
     ...

ğŸ’¡ INTUITION:
  â€¢ Chaque tÃªte capture DIFFÃ‰RENTES dÃ©pendances.
  â€¢ TÃªte 0 peut se concentrer sur sujet-verbe.
  â€¢ TÃªte 1 peut se concentrer sur verbe-adverbe.
```

---

### Script 3 : TempÃ©rature et Softmax (Chapitres 7 & 11)

**Voir:** `07-preentrainement-llms.md`, `11-strategies-generation-inference.md`

Montre l'effet de la tempÃ©rature sur la distribution softmax :
- Basse T â†’ distribution pointue (greedy, dÃ©terministe).
- Haute T â†’ distribution plate (diversitÃ©, crÃ©ativitÃ©).
- Lien avec l'entropie.

```bash
python 03_temperature_softmax.py
```

**Exemple de sortie:**
```
TempÃ©rature = 0.1
  ProbabilitÃ©s:
    chat    : 1.000  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    chien   : 0.000
    souris  : 0.000
    oiseau  : 0.000
  Entropie: 0.001

TempÃ©rature = 5.0
  ProbabilitÃ©s:
    chat    : 0.308  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    chien   : 0.252  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    souris  : 0.228  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    oiseau  : 0.211  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  Entropie: 1.376

âœ“ Ã€ T=0.1 â†’ DÃ©terministe (distribution pointue, 'chat' domine Ã  100%).
âœ“ Ã€ T=5.0 â†’ Quasi-uniforme (distribution plate, tous les tokens similaires).
âœ“ T=0.7-0.9 â†’ Bon compromis crÃ©ativitÃ©/stabilitÃ©.
```

GÃ©nÃ¨re optionnellement un graphique : `temperature_effect.png`

---

### Script 4 : RAG Minimaliste (Chapitre 13)

**Voir:** `13-systemes-augmentes-agents.md`

Simule un pipeline RAG complet :
1. **Retrieval** : chercher les 3 documents les plus pertinents.
2. **Augmentation** : injecter le contexte dans le prompt.
3. **GÃ©nÃ©ration** : le LLM rÃ©pond en s'appuyant sur le contexte.

```bash
python 04_rag_minimal.py
```

**Exemple de sortie:**
```
Question: "Comment fonctionne l'attention dans le Transformer?"

Top 3 documents rÃ©cupÃ©rÃ©s:
1. Score: 0.223
   Le Transformer est une architecture basÃ©e sur l'attention multi-tÃªte.

2. Score: 0.102
   Le Transformer a Ã©tÃ© introduit en 2017 par Vaswani et ses collÃ¨gues.

Prompt augmentÃ© envoyÃ© au LLM:
---
Vous Ãªtes un assistant expert.

Voici des documents pertinents:
- L'attention multi-tÃªte permet...
- Le Transformer est une architecture...
- ...

Question: Comment fonctionne l'attention dans le Transformer?

RÃ©ponse basÃ©e sur les documents:
---

COMPARAISON:
âŒ SANS RAG:
  â†’ Hallucination possible
  â†’ Connaissances figÃ©es
  â†’ Pas de sources Ã  vÃ©rifier

âœ… AVEC RAG:
  â†’ RÃ©ponses basÃ©es sur des sources
  â†’ AccÃ¨s aux donnÃ©es externes
  â†’ Utilisateur peut vÃ©rifier les sources
```

---

### Script 5 : Ã‰valuation Pass@k (Chapitre 12)

**Voir:** `12-modeles-raisonnement.md`

Ã‰value la fiabilitÃ© d'un modÃ¨le sur des tÃ¢ches vÃ©rifiables :
- **Pass@k** : probabilitÃ© d'au moins **une** rÃ©ussite en k tentatives.
- **Pass^k** : probabilitÃ© que **toutes** les k tentatives rÃ©ussissent.

```bash
python 05_pass_at_k_evaluation.py
```

**Exemple de sortie:**
```
ParamÃ¨tres:
  â€¢ Nombre de tentatives: 100
  â€¢ ProbabilitÃ© de succÃ¨s: 30%

PASS@K (Au moins UNE rÃ©ussite en k tentatives):
Pass@1  = 34.0% (1 tentative)
Pass@3  = 71.3% (3 tentatives)
Pass@5  = 87.5% (5 tentatives)
Pass@10 = 98.4% (10 tentatives)

PASS^K (TOUTES les k tentatives rÃ©ussissent) â€” STRICT:
Pass^1 = 34.0% empirique / 30.0% thÃ©orique (0.3^1)
Pass^3 =  0.0% empirique /  2.7% thÃ©orique (0.3^3)
Pass^5 =  0.0% empirique /  0.2% thÃ©orique (0.3^5)

APPLICATION:
  âœ“ Recherche (HumanEval): Pass@k (diversitÃ©)
  âœ“ Agents critiques: Pass^k (fiabilitÃ© totale)
```

---

## ğŸ¯ Comment Utiliser Ces Scripts

### Pour les Ã‰tudiants

1. **Lisez le chapitre pertinent du livre.**
2. **ExÃ©cutez le script associÃ©.**
3. **Modifiez les paramÃ¨tres** pour voir les effets :
   - Changez `seq_len`, `num_heads`, `temperatures`, etc.
   - Ajoutez vos propres textes/documents.
4. **Ajoutez des `print()`** pour dÃ©boguer et comprendre les dimensions.

### Pour les IngÃ©nieurs

- Utilisez ces scripts comme **point de dÃ©part** pour vos implÃ©mentations.
- IntÃ©grez-les dans des **pipelines de production** (RAG, Ã©valuation, etc.).
- Adaptez le code Ã  votre **infrastructure** (GPUs, APIs, bases de donnÃ©es).

## ï¿½ Projet IntÃ©grateur : Mini-Assistant Complet (`09_mini_assistant_complet.py`)

**Voir:** Chapitres 11-15 du livre

Ce script final **assemble TOUS les concepts du livre** en un systÃ¨me cohÃ©rent :
- **RAG (Ch. 13)** : Indexation vectorielle TF-IDF et recherche par similaritÃ©
- **Agents ReAct (Ch. 14)** : Boucle Thoughtâ†’Actionâ†’Observation avec tool calling
- **Prompting (Ch. 11)** : Zero-shot, Few-shot, Chain-of-Thought pour structures les rÃ©ponses
- **Ã‰valuation (Ch. 12, 15)** : Confiance, self-consistency, mÃ©triques de qualitÃ©
- **Outils** : Calculatrice, recherche, horloge, rÃ©sumÃ©

**Parcours pÃ©dagogique du chapitre 11 au 15 :**

1. **Chapitre 11 (Prompting)** â†’ Structurer les demandes avec Chain-of-Thought
2. **Chapitre 12 (Ã‰valuation)** â†’ Mesurer la qualitÃ© avec Pass@k et confiance
3. **Chapitre 13 (RAG)** â†’ Augmenter le contexte avec documents pertinents
4. **Chapitre 14 (Agents)** â†’ Boucle autonome avec tool calling et rÃ©actions
5. **Chapitre 15 (Mise en production)** â†’ Assembler tout cela en systÃ¨me robuste

**Phases d'exÃ©cution :**
1. Initialisation de la base de connaissances (5 documents dÃ©mo)
2. CrÃ©ation de l'agent avec 4 outils enregistrÃ©s
3. Traitement de 3 questions test
4. Ã‰valuation des rÃ©ponses (itÃ©rations, confiance, succÃ¨s)
5. **Bonus** : Test de self-consistency (mÃªme question, 3 essais)
6. Rapport global des performances

**ExÃ©cution :**
```bash
python 09_mini_assistant_complet.py
```

**Exemple de sortie :**
```
ğŸš€ MINI-ASSISTANT COMPLET - PROJET INTÃ‰GRATEUR

ğŸ“š Phase 1 : Initialisation de la base de connaissances
âœ“ Index crÃ©Ã© : 5 documents indexÃ©s

ğŸ¤– Phase 2 : CrÃ©ation de l'agent
âœ“ Agent crÃ©Ã© avec 4 outils

ğŸ’¬ Phase 3 : Questions de test

ğŸ¤– Question : Qu'est-ce qu'un Transformer ?
ğŸ’­ PensÃ©e : Je dois chercher des informations sur transformer
ğŸ”§ Action : search(query='transformer')
ğŸ“Š Observation : Documents trouvÃ©s:
  [Architecture Transformer] (score: 0.89)
  Les Transformers sont une architecture...

âœ… RÃ©ponse finale : Les Transformers sont une architecture...

ğŸ“Š Phase 4 : Rapport d'Ã©valuation
Question 1 : Qu'est-ce qu'un Transformer ?
  â€¢ ItÃ©rations : 1
  â€¢ Confiance : 100.00%
  â€¢ SuccÃ¨s : âœ…

ğŸ“ˆ Statistiques globales
  â€¢ Nombre de questions : 3
  â€¢ ItÃ©rations moyennes : 1.3
  â€¢ Confiance moyenne : 88.33%
  â€¢ Taux de succÃ¨s : 100.00%
```

**Points d'extension pour les Ã©tudiants :**
1. IntÃ©grer OpenAI, Claude ou un modÃ¨le local (Ollama)
2. Ajouter de nouveaux outils (mÃ©tÃ©o, API, base de donnÃ©es)
3. Persister les conversations (SQLite, PostgreSQL)
4. CrÃ©er une interface web (Streamlit, Gradio, FastAPI)
5. ImplÃ©menter des mÃ©triques avancÃ©es (ROUGE, BERTScore)
6. GÃ©rer les contexts longs et la pagination
7. DÃ©ployer en production (Docker, Kubernetes)

---

## ğŸ Autres Bonus Scripts

### BONUS 1 : ReAct Agent Framework (`06_react_agent_bonus.py`)

**Voir:** `REACT_AGENT_INTEGRATION.md`

Framework complet pour construire des **agents autonomes avec pattern ReAct**.

**CaractÃ©ristiques:**
- âœ… Classe `Agent` rÃ©utilisable et extensible
- âœ… SystÃ¨me de registration d'outils (tool definition)
- âœ… Boucle Thought â†’ Action â†’ Observation
- âœ… LLM simulation (prÃªt pour OpenAI, Claude, Groq, Ollama)
- âœ… Historique et gestion d'itÃ©rations
- âœ… Exemple avec 3 outils (calculator, date, knowledge base)

**Concepts couverts:**
- Agents autonomes (Chapitre 13)
- Protocoles standards agentiques (Chapitre 14)
- Pattern ReAct (Reasoning + Acting)
- Tool calling et execution

**ExÃ©cution:**
```bash
python 06_react_agent_bonus.py
```

**IntÃ©gration avec LLMs rÃ©els:**
```python
from openai import OpenAI

class OpenAIAgent(Agent):
    def _simulate_llm_reasoning(self, task, context):
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
```

Voir `REACT_AGENT_INTEGRATION.md` pour intÃ©grations complÃ¨tes (OpenAI, Claude, Groq, Ollama).

---

### BONUS 2 : LlamaIndex RAG AvancÃ© (`07_llamaindex_rag_advanced.py`)

**Voir:** `LLAMAINDEX_GUIDE.md`

Framework complet pour construire des **systÃ¨mes RAG avancÃ©s avec LlamaIndex**.

**CaractÃ©ristiques:**
- âœ… Indexation vectorielle d'documents
- âœ… Retrieval avancÃ© (similarity search, hybrid BM25+vector)
- âœ… RAG Engine avec augmentation de contexte
- âœ… Chatbot avec mÃ©moire conversationnelle
- âœ… Ã‰valuation de qualitÃ© (Precision, Recall, F1)
- âœ… Export des rÃ©sultats en JSON
- âœ… Fallback embeddings simulÃ©s (pas de dÃ©pendances requises)

**Concepts couverts:**
- RAG (Retrieval-Augmented Generation) - Chapitre 13
- Document parsing et indexing
- Vector similarity search
- Query augmentation avec contexte
- Conversation avec persistance

**Phases d'exÃ©cution:**
1. Chargement des documents
2. CrÃ©ation de l'index vectoriel
3. Initialisation du RAG Engine
4. RequÃªtes RAG avec retrieval
5. Chat avec mÃ©moire
6. Ã‰valuation de qualitÃ©
7. Export des rÃ©sultats

**ExÃ©cution sans dÃ©pendances:**
```bash
python 07_llamaindex_rag_advanced.py
```
âš ï¸ Utilise embeddings simulÃ©s (dÃ©terministes).

**ExÃ©cution avec LlamaIndex rÃ©el:**
```bash
pip install llama-index openai
python 07_llamaindex_rag_advanced.py
```
âœ“ Utilise OpenAI embeddings (text-embedding-3-small).

**Production avec documents rÃ©els:**
```python
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader

# Charger PDFs, Word, HTML, etc.
documents = SimpleDirectoryReader("./docs").load_data()

# CrÃ©er index
index = VectorStoreIndex.from_documents(documents)

# Query engine
query_engine = index.as_query_engine(similarity_top_k=3)
response = query_engine.query("Votre question ici")
```

Voir `LLAMAINDEX_GUIDE.md` pour :
- Installation complÃ¨te (LlamaIndex, vector stores, readers)
- IntÃ©gration OpenAI, Claude, Groq
- Hybrid search (BM25 + vectoriel)
- Agents avec outils
- Ã‰valuation de qualitÃ©
- Cas d'usage avancÃ©s

---

### Script 8 : LoRA & QLoRA Fine-tuning (Chapitre 9) ğŸ BONUS 3

**Voir:** `09-affinage-supervise-sft.md`

DÃ©montre les techniques de fine-tuning efficace en ressources :
- LoRA (Low-Rank Adaptation) : rÃ©duction des paramÃ¨tres entraÃ®nables.
- QLoRA (Quantized LoRA) : quantification + LoRA pour VRAM ultra-faible.
- Comparaison chiffrÃ©e : Full Fine-tuning vs LoRA vs QLoRA.
- Cas rÃ©el : adaptation d'un modÃ¨le LLaMA-7B pour le domaine ferroviaire (SNCF).

```bash
python 08_lora_finetuning_example.py
```

**Exemple de sortie:**
```
================================================================================
EXEMPLE 1 : Fine-tuner LLaMA-7B
================================================================================

ModÃ¨le : LLaMA-7B (7.0B paramÃ¨tres)
LoRA rank : 8

Comparaison des mÃ©thodes :
MÃ©thode              Params          VRAM      Temps   Cas d'usage
full_fine_tuning     7000.0M        26.1GB     1.0x  â†’ Meilleure performance
lora                    2.1M         6.5GB     0.3x  â†’ Bon compromis
qlora                   2.1M         1.6GB     0.4x  â†’ RÃ‰VOLUTION : fine-tune sur GPU basic

INSIGHT :
  â€¢ Full fine-tuning : 28 GB VRAM â†’ nÃ©cessite A100 ou RTX 6000
  â€¢ LoRA : 8 GB VRAM â†’ entraÃ®nable sur RTX 4090 (24 GB)
  â€¢ QLoRA : 2 GB VRAM â†’ entraÃ®nable sur RTX 3090 âœ… RÃ‰VOLUTION!
```

Concepts abordÃ©s :
- W = Wâ‚€ + BA (dÃ©composition LoRA)
- Effet du rank (8, 16, 32, 64) sur taille vs performance
- Quantisation 8-bit et Ã©conomies de mÃ©moire
- Peft library integration (transformers + peft)
- Pseudo-code pour adapter modÃ¨les multilingues

---

## ğŸ“š Correspondance Livre â†” Scripts

| Chapitre | Topic | Script |
|----------|-------|--------|
| 2 | Tokenisation, Embeddings | `01_tokenization_embeddings.py` |
| 3 | Architecture Transformer, Attention | `02_multihead_attention.py` |
| 7 | PrÃ©-entraÃ®nement, Loss | `03_temperature_softmax.py` |
| 9 | Affinage supervisÃ©, LoRA, QLoRA | **`08_lora_finetuning_example.py`** |
| 11 | StratÃ©gies de gÃ©nÃ©ration, TempÃ©rature | `03_temperature_softmax.py` |
| 12 | ModÃ¨les de raisonnement, Ã‰valuation | `05_pass_at_k_evaluation.py` |
| 13 | SystÃ¨mes augmentÃ©s, RAG, Agents | `04_rag_minimal.py`, **`06_react_agent_bonus.py`**, **`07_llamaindex_rag_advanced.py`** |
| 14 | Protocoles standards agentiques | **`06_react_agent_bonus.py`** |
| **11-15** | **Projet IntÃ©grateur Complet** | **`09_mini_assistant_complet.py`** |

### Parcours PÃ©dagogique RecommandÃ©

**Phase 1 : Fondamentaux (Chapitres 1-7)**
â†’ ExÃ©cutez les scripts 1, 2, 3 pour comprendre les mÃ©caniques de base

**Phase 2 : Ã‰valuation et RAG (Chapitres 9-13)**
â†’ Scripts 5, 4, 6, 7, 8 pour maÃ®triser Ã©valuation, retrieval, agents avancÃ©s

**Phase 3 : IntÃ©gration (Chapitres 11-15)** â† **Vous Ãªtes ici**
â†’ **Script 9** : Assembler tous les concepts en un mini-assistant cohÃ©rent
â†’ Comprendre comment RAG + Agents + Prompting + Ã‰valuation travaillent ensemble
â†’ Point d'ancrage pour vos propres extensions en production

---

## ğŸ† Projet IntÃ©grateur : Mini-Assistant Complet (`09_mini_assistant_complet.py`)

**LE script phare** : intÃ¨gre TOUS les concepts des chapitres 11-15 en un seul projet exÃ©cutable.

### ğŸ“ Localisation dans le parcours pÃ©dagogique

| Chapitre | Sujet | UtilisÃ© Dans ? |
|----------|-------|---|
| **11** | StratÃ©gies de gÃ©nÃ©ration et infÃ©rence | âœ… TempÃ©rture, top-k, top-p |
| **12** | ModÃ¨les de raisonnement (CoT, ToT) | âœ… Chain-of-Thought prompt |
| **13** | SystÃ¨mes augmentÃ©s et agents (RAG) | âœ… Retrieval + indexing |
| **14** | Protocoles standards agentiques (MCP) | âœ… Tool registration, agents |
| **15** | Ã‰valuation critique des flux agentiques | âœ… MÃ©triques + Ã©valuation |

### ğŸ¯ Fonction du script

L'assistant dÃ©montre :
1. **Contexte Enrichi** : RAG pour mÃ©moire externe
2. **Raisonnement** : Chain-of-Thought reasoning
3. **AgentivitÃ©** : Agent auto-suffisant prenant des dÃ©cisions
4. **Ã‰valuation** : MÃ©triques BLEU, embedding similarity, cohÃ©rence

### ğŸš€ ExÃ©cuter

```bash
python 09_mini_assistant_complet.py
```

**Voir aussi:**
- [INDEX_SCRIPT_09.md](INDEX_SCRIPT_09.md) - Vue d'ensemble architecture
- [QUICKSTART_SCRIPT_09.md](QUICKSTART_SCRIPT_09.md) - Guide dÃ©marrage rapide
- [SCRIPT_09_MAPPING.md](SCRIPT_09_MAPPING.md) - Correspondance concepts â†” code

---

## ğŸ Autres Bonus Scripts

### Bonus 1 : ReAct Agent (`06_react_agent_bonus.py`)

Pattern **ReAct** (Reasoning + Acting) avec framework gÃ©nÃ©rique, tool registration et 3 outils d'exemple.

**Voir:** [REACT_AGENT_INTEGRATION.md](REACT_AGENT_INTEGRATION.md)

### Bonus 2 : RAG AvancÃ© (`07_llamaindex_rag_advanced.py`)

Framework RAG complet : document ingestion, indexing, 6 phases d'exÃ©cution, export JSON.

**Voir:** [LLAMAINDEX_GUIDE.md](LLAMAINDEX_GUIDE.md)

### Bonus 3 : LoRA Fine-Tuning (`08_lora_finetuning_example.py`)

Techniques d'optimisation : LoRA, QLoRA, comparaison fine-tuning.

---

## ğŸ“– Correspondance Livre â†” Scripts (Parcours PÃ©dagogique)

```
ğŸ“– Chapitres du Livre                  â†’  ğŸ’» Scripts Correspondants
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Ch. 2  : ReprÃ©sentation texte         â†’  01_tokenization_embeddings.py
Ch. 3  : Architecture Transformer     â†’  02_multihead_attention.py
Ch. 7  : PrÃ©-entraÃ®nement             â†’  03_temperature_softmax.py
Ch. 9  : Fine-tuning                  â†’  08_lora_finetuning_example.py ğŸ
Ch. 11 : GÃ©nÃ©ration & InfÃ©rence       â†’  03_temperature_softmax.py (bis)
                                       â†’  09_mini_assistant_complet.py ğŸ†
Ch. 12 : Raisonnement & Ã‰valuation    â†’  05_pass_at_k_evaluation.py
                                       â†’  09_mini_assistant_complet.py ğŸ†
Ch. 13 : SystÃ¨mes AugmentÃ©s (RAG)     â†’  04_rag_minimal.py
                                       â†’  07_llamaindex_rag_advanced.py ğŸ
                                       â†’  09_mini_assistant_complet.py ğŸ†
Ch. 14 : Protocoles Agentiques (MCP)  â†’  06_react_agent_bonus.py ğŸ
                                       â†’  09_mini_assistant_complet.py ğŸ†
Ch. 15 : Ã‰valuation Critique          â†’  09_mini_assistant_complet.py ğŸ†
```

---

## ğŸ› ï¸ Troubleshooting

### "ModuleNotFoundError: No module named 'transformers'"

```bash
pip install transformers
```

### "ModuleNotFoundError: No module named 'torch'"

```bash
# CPU
pip install torch

# GPU (CUDA 12.1)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### Matplotlib non installÃ©

```bash
pip install matplotlib
# Script 3 continuera Ã  fonctionner sans, mais pas de graphique.
```

### Script trop lent (transformers qui tÃ©lÃ©charge un modÃ¨le)

- Les modÃ¨les se tÃ©lÃ©chargent automatiquement Ã  la premiÃ¨re exÃ©cution (~3 GB pour LLaMA).
- Les prochaines exÃ©cutions seront plus rapides (cache local).
- Alternative : utiliser un modÃ¨le plus petit (`distilbert-base-multilingual-cased`).

## ğŸ“ Notes

- **Pas de GPU requis** : tous les scripts tournent sur CPU (plus lentement).
- **DÃ©pendances minimales** : seulement `numpy`, `torch`, `transformers`, `scikit-learn`.
- **Code Ã©ducatif** : les scripts privilÃ©gient la clartÃ© sur l'optimisation.
- **Compatible Python 3.9+**.
- **Scripts bonus** : dÃ©montrent des concepts avancÃ©s, fonctionnent sans LLM externe (mode simulation).

---

**Bon apprentissage! ğŸš€**
